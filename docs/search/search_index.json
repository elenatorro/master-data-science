{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Apuntes y ejercicios de Elena Torr\u00f3 Mart\u00ednez","title":"Principal"},{"location":"asignaturas/primer_cuatrimestre/mineria_de_textos/1_procesamiento_lenguaje_natural/","text":"Introducci\u00f3n al Procesamiento del Lenguaje Natural \u00b6 Miner\u00eda de Textos \u00b6 Proceso de analizar colecciones de textos para descubrir informacio\u0301n y patrones que no aparecen de forma expli\u0301cita en los textos. Qu\u00e9 hace \u00b6 Extraccio\u0301n y recuperaci\u00f3n de informacio\u0301n Categorizacio\u0301n y agrupamiento de documentos C\u00f3mo lo hace \u00b6 Se utilizan t\u00e9cnicas de procesamiento del lenguaje natural y de aprendizaje automa\u0301tico . Se aplica a colecciones de documentos con informacio\u0301n textual no estructurada y escrita en lenguaje natural Informaci\u00f3n Textual \u00b6 Documentos que pueden agruparse en colecciones o corpus . Pueden contener anotaciones y metadatos . Extracci\u00f3n de Informaci\u00f3n \u00b6 Extraer automa\u0301ticamente informacio\u0301n estructurada a partir de textos. Abarca procesos como: NER: Named Entity Recognition, o reconocimiento de nombre de entidades. Extracci\u00f3n de terminolog\u00eda y de relaciones. Information Retrieval: recuperaci\u00f3n de informaci\u00f3n. Buscar documentos Buscar informaci\u00f3n dentro de los documentos Buscar informaci\u00f3n en los metadatos que describan los documentos Buscar en distintas fuentes de datos Categorizaci\u00f3n de Documentos \u00b6 Asignar a un documento una o ma\u0301s categori\u0301as definidas previamente en funcio\u0301n de su contenido. Agrupamiento de Documentos \u00b6 Document Clustering Forma de organizacio\u0301n de documentos en grupos en la que ni la naturaleza de los grupos, ni en ocasiones su nu\u0301mero esta\u0301n definidos de antemano. Procesamiento del Lenguaje Natural \u00b6 (PLN \u00f3 NLP, Natural Languaje Processing) Rama de la informa\u0301tica cuyo objetivo es el desarrollo de sistemas que permitan a los ordenadores comunicarse con personas utilizando el lenguaje humano. Se utiliza para adquirir conocimientos a partir de cantidades masivas de datos textuales Retos NLP \u00b6 Alta ambigu\u0308edad a todos los niveles: Le\u0301xico, Sinta\u0301ctico, Sema\u0301ntico, de discursos Conocimiento del mundo (contexto, situaci\u00f3n, jerga...) Interpretar correctamente: Negacio\u0301n: al extraer la informacio\u0301n es importante saber si un dato, concepto, relacio\u0301n etc. esta\u0301 siendo negado. Especulacio\u0301n: Muchas veces se dice que \u201cpuede\u201d darse un hecho. Correferencia: es necesario identificar expresiones que hacen referencia a la misma entidad (Aunque todos vieron al Presidente , ninguno reconocio\u0301 al ganador de las u\u0301ltimas elecciones ) Evaluaci\u00f3n de Tareas \u00b6 Es necesario obtener datos de evaluacio\u0301n de los modelos y sistemas para el avance del a\u0301rea. Es necesario comparar modelos y sistemas de formas justa: Sobre los mismos datos: corpus o colecciones comunes Usando las mismas medidas Corpus \u00b6 Un corpus es una compilacio\u0301n de textos en formato electro\u0301nico. Son un recurso fundamental en el desarrollo de aplicaciones basadas en PLN: * Permiten evaluar los sistemas * Proporcionan un marco comu\u0301n para comparar te\u0301cnicas alternativas * Permiten entrenar los sistemas de aprendizaje automa\u0301tico supervisados: ajustan sus para\u0301metros a partir de una parte del corpus usada para entrenamiento. * Proporcionan una muestra amplia y natural del lenguaje. * Son una fuente de datos estadi\u0301sticos sobre las palabras, sus relaciones y sus construcciones. Aplicaciones \u00b6 Asignacio\u0301n automa\u0301tica de categori\u0301as le\u0301xicas Desambiguacio\u0301n sinta\u0301ctica Extraccio\u0301n de grama\u0301ticas Traduccio\u0301n automa\u0301tica Extraccio\u0301n de entidades (nombres, medicamentos, etc.) Extraccio\u0301n de relaciones Tipos generales \u00b6 Sin anotar: Texto puro Anotados: marcados con distintos tipos de informacio\u0301n lingu\u0308i\u0301stica (se les denomina Gold standard y se usan de referencia) Monolingu\u0308e: textos pertenecientes a una u\u0301nica lengua Multilingu\u0308e: textos en diversas lenguas. Proporcionan anotaciones similares en distintas lenguas Paralelo: contiene los mismos textos en ma\u0301s de una lengua Comparable: Contiene un nu\u0301mero equilibrado de textos en distintas lenguas. Tambie\u0301n esta\u0301n equilibrados respecto al tema y tipo de textos Ejemplos \u00b6 Corpus de Brown http://www.nltk.org/nltk_data Palabras anotadas (+1M) Categor\u00edas l\u00e9xicas 87 Etiquetas Corpus de Susanne http://www.nltk.org/nltk_data Palabras (+130K) Subconjunto de 64 archivos del corpus de Brown Anotado con categori\u0301as le\u0301xicas y ana\u0301lisis sinta\u0301ctico Por cada palabra de texto hay una li\u0301nea de anotaciones (ana\u0301lisis sinta\u0301ctico) Corpus ADE https://github.com/trunghlt/AdverseDrugReaction Relaciones entre efectos adversos y medicamentos Corpus Bioscope: http://rgai.inf.u-szeged.hu/index.php?lang=en&page=bioscope Textos biome\u0301dicos anotados con negacio\u0301n y especulacio\u0301n Corpus DDI: https://omictools.com/ddi-corpus-tool Anotacio\u0301n de medicamentos e interacciones entre ellos: The DDI corpus: an annotated corpus with pharmacological substances and drug-drug interactions. Corpus Europarl: http://www.statmt.org/europarl/ Actas del parlamento europeo en 21 lenguas de Europa: Espan\u0303ol, Ingle\u0301s, France\u0301s, Griego, ..., con alineamiento o correspondencia a nivel de oracio\u0301n) Corpus DIANN https://github.com/gildofabregat/DIANN-IBEREVAL-2018/tree/master/DIANN_CORPUS Discapacidades anotadas Evaluaci\u00f3n de Tareas \u00b6 Campan\u0303as de evaluacio\u0301n \u00b6 Proponen retos a los participantes, proporcionando datos y un marco de evaluacio\u0301n comu\u0301n y bien definido. * TREC: Text Retrieval conference * CLEF: Conference and Labs of the evaluation Forum * Semeval: Semantic Evaluation Ibereval: Lenguas Ibe\u0301ricas Medidas de Evaluaci\u00f3n \u00b6 Precisio\u0301n : fraccio\u0301n de predicciones del modelo propuesto acertadas (coinciden con los datos de referencia) precission = true positive / (true positive + false positive) Recall : Cobertura o exhaustividad. Fraccio\u0301n de los datos de referencia que han sido propuestas por el modelo evaluado: recall = true positive / (true positive + false negative) Medida-F: media armo\u0301nica de precisio\u0301n y cobertura: meassure_f = 2 * precission * recall / (precission + recall) Medida-F\u03b2: forma general de la media armo\u0301nica que permite dar ma\u0301s importancia a la precisio\u0301n o a la cobertura en funcio\u0301n del para\u0301metro \u03b2: meassure_f_beta = ((1 + \u03b2^2) * precission * recall) / (\u03b2^2 * (precission + recall)) Ejemplo \u00b6 Tenemos: N\u00famero de datos totales: 16 N\u00famero de datos del modelo: 13 N\u00famero de datos que usa el modelo: 8 (true positive) N\u00famero de datos aportados: 11 Falsos negativos: 11 - 8 = 3 Falsos positivos: 13 - 8 = 5 Medidas: Precisi\u00f3n 8 / 8 + 5 = 8 / 13 Medida_F 8 / 8 + 3 = 8 / 11 Herramientas \u00b6 Nltk: Natural Language Toolkit Libreri\u0301a para desarrollar programas en python para procesar datos de lenguaje natural https://www.nltk.org/ Ejemplos de como iniciarlo, y algunas de las utilidades ma\u0301s ba\u0301sicas: https://www.nltk.org/book/ch01.html Spacy: Libreri\u0301a para desarrollar programas en python para procesar datos de lenguaje natural https://spacy.io/ Tiene modelos preentrenados en Ingl\u00e9s y Espa\u00f1ol Procesos \u00b6 Normalizacio\u0301n: Unificar palabras que se refieren de distinta forma a la misma entidad Expresiones regulares: Especificar patrones de texto Distancia de edicio\u0301n: Nu\u0301mero/coste de las operaciones de edicio\u0301n: Insercio\u0301n, Borrado, Sustitucio\u0301n Necesarias para transformar una cadena en la otra. Explorar todas las combinaciones de operacio\u0301n para seleccionar la de menor coste Importante para medir la similitud entre dos cadenas Se usan para correcci\u00f3n de errores ortogr\u00e1ficos, extracci\u00f3n de informaci\u00f3n... Identificar palabras vac\u00edas: Palabras sin significado propio: arti\u0301culos, preposiciones, etc. Suelen ser las ma\u0301s frecuentes en un idioma En muchos procesos de PLN se eliminan para centrar el ana\u0301lisis en las palabras con contenido sema\u0301ntico Segmentaci\u00f3n de cadenas: Romper una cadena de caracteres (grafemas) en una secuencia de palabras. POS tagging Part-Of-Speech Tagging: Etiquetar las palabras de una oracio\u0301n con su categori\u0301a le\u0301xica seg\u00fan su definici\u00f3n y el contexto de la oraci\u00f3n Cada palabra de una oracio\u0301n se puede clasificar en clases: verbos, adjetivos, nombres, etc \u00datil para: Identificacio\u0301n de entidades, desambiguacio\u0301n del sentido de las palabras, an\u00e1lisis sint\u00e1ctico... T\u00e9cnicas: Basados en reglas, modelo de probabilidades de las secuencias de palabras y sus etiquetas en funcio\u0301n de los datos de un corpus anotado, aprendizaje autom\u00e1tico. Evaluaci\u00f3n: Accuracy: nu\u0301mero de etiquetas acertadas sobre el nu\u0301mero total de palabras etiquetadas Precisio\u0301n, cobertura y medida-F para cada tipo de etiqueta del conjunto de etiquetas considerado Stemming An\u00e1lisis morfol\u00f3gico El proceso de stemming se refiere al proceso de eliminar la parte final de las palabras, que en muchas ocasiones es una aproximacio\u0301n a la lematizacio\u0301n. Permite reconocer todas las palabras correspondiente a una misma rai\u0301z Chunking Parte en trozos (chunks) y etiqueta secuencias multipalabra NP-chunks suelen ser menores que las frases nominales: NP-chunks no contienen otros NP-chunks Los sintagmas preposicionales o las cla\u0301usulas subordinadas que modifican un nominal no se suelen incluir. Se puede construir una gramatica de deteccio\u0301n de chunks usando expresiones regulares sobre las etiquetas POS. (pag. 265 libro nltk) Tambie\u0301n puede construirse con clasificadores entrenados. An\u00e1lisis Sint\u00e1ctico: Identificar la estructura sinta\u0301ctica de una oracio\u0301n. La estructura asignada depende del tipo de grama\u0301tica considerada. Dificultad: ambigu\u0308edad estructural \u2192 una oracio\u0301n puede tener mu\u0301ltiples a\u0301rboles de ana\u0301lisis respecto a una misma grama\u0301tica Desambiguacio\u0301n del sentido de las palabras Muchas palabras tiene ma\u0301s de un significado o sentido dependiendo del contexto en que se usan Muchas aplicaciones requieren seleccionar el sentido correcto: Word Sense Disambiguation (WSD). Relaciones entre sentidos: Sino\u0301nimos: distintas palabras con el mismo (o muy similar) significado Hipo\u0301nimo: un sentido es hipo\u0301nimo de otro si el primero es ma\u0301s especi\u0301fico (una subclase). Hipero\u0301nimo: un sentido es hipero\u0301nimo de otro si el primero es ma\u0301s general (superclase) Wordnet: una base de datos de relaciones le\u0301xicas Ana\u0301lisis morfololo\u0301gico \u00b6 La morfologi\u0301a es el campo de la lingu\u0308i\u0301stica que estudia la estructura de las palabras Un morfema es la unidad lingu\u0308i\u0301stica ma\u0301s pequen\u0303a que tiene significado sema\u0301ntico El ana\u0301lisis morfolo\u0301gico es la tarea de segmentar una palabra en sus morfemas","title":"Tema 1. Procesamiento del Lenguaje Natural"},{"location":"asignaturas/primer_cuatrimestre/mineria_de_textos/1_procesamiento_lenguaje_natural/#introduccion-al-procesamiento-del-lenguaje-natural","text":"","title":"Introducci\u00f3n al Procesamiento del Lenguaje Natural"},{"location":"asignaturas/primer_cuatrimestre/mineria_de_textos/1_procesamiento_lenguaje_natural/#mineria-de-textos","text":"Proceso de analizar colecciones de textos para descubrir informacio\u0301n y patrones que no aparecen de forma expli\u0301cita en los textos.","title":"Miner\u00eda de Textos"},{"location":"asignaturas/primer_cuatrimestre/mineria_de_textos/1_procesamiento_lenguaje_natural/#que-hace","text":"Extraccio\u0301n y recuperaci\u00f3n de informacio\u0301n Categorizacio\u0301n y agrupamiento de documentos","title":"Qu\u00e9 hace"},{"location":"asignaturas/primer_cuatrimestre/mineria_de_textos/1_procesamiento_lenguaje_natural/#como-lo-hace","text":"Se utilizan t\u00e9cnicas de procesamiento del lenguaje natural y de aprendizaje automa\u0301tico . Se aplica a colecciones de documentos con informacio\u0301n textual no estructurada y escrita en lenguaje natural","title":"C\u00f3mo lo hace"},{"location":"asignaturas/primer_cuatrimestre/mineria_de_textos/1_procesamiento_lenguaje_natural/#informacion-textual","text":"Documentos que pueden agruparse en colecciones o corpus . Pueden contener anotaciones y metadatos .","title":"Informaci\u00f3n Textual"},{"location":"asignaturas/primer_cuatrimestre/mineria_de_textos/1_procesamiento_lenguaje_natural/#extraccion-de-informacion","text":"Extraer automa\u0301ticamente informacio\u0301n estructurada a partir de textos. Abarca procesos como: NER: Named Entity Recognition, o reconocimiento de nombre de entidades. Extracci\u00f3n de terminolog\u00eda y de relaciones. Information Retrieval: recuperaci\u00f3n de informaci\u00f3n. Buscar documentos Buscar informaci\u00f3n dentro de los documentos Buscar informaci\u00f3n en los metadatos que describan los documentos Buscar en distintas fuentes de datos","title":"Extracci\u00f3n de Informaci\u00f3n"},{"location":"asignaturas/primer_cuatrimestre/mineria_de_textos/1_procesamiento_lenguaje_natural/#categorizacion-de-documentos","text":"Asignar a un documento una o ma\u0301s categori\u0301as definidas previamente en funcio\u0301n de su contenido.","title":"Categorizaci\u00f3n de Documentos"},{"location":"asignaturas/primer_cuatrimestre/mineria_de_textos/1_procesamiento_lenguaje_natural/#agrupamiento-de-documentos","text":"Document Clustering Forma de organizacio\u0301n de documentos en grupos en la que ni la naturaleza de los grupos, ni en ocasiones su nu\u0301mero esta\u0301n definidos de antemano.","title":"Agrupamiento de Documentos"},{"location":"asignaturas/primer_cuatrimestre/mineria_de_textos/1_procesamiento_lenguaje_natural/#procesamiento-del-lenguaje-natural","text":"(PLN \u00f3 NLP, Natural Languaje Processing) Rama de la informa\u0301tica cuyo objetivo es el desarrollo de sistemas que permitan a los ordenadores comunicarse con personas utilizando el lenguaje humano. Se utiliza para adquirir conocimientos a partir de cantidades masivas de datos textuales","title":"Procesamiento del Lenguaje Natural"},{"location":"asignaturas/primer_cuatrimestre/mineria_de_textos/1_procesamiento_lenguaje_natural/#retos-nlp","text":"Alta ambigu\u0308edad a todos los niveles: Le\u0301xico, Sinta\u0301ctico, Sema\u0301ntico, de discursos Conocimiento del mundo (contexto, situaci\u00f3n, jerga...) Interpretar correctamente: Negacio\u0301n: al extraer la informacio\u0301n es importante saber si un dato, concepto, relacio\u0301n etc. esta\u0301 siendo negado. Especulacio\u0301n: Muchas veces se dice que \u201cpuede\u201d darse un hecho. Correferencia: es necesario identificar expresiones que hacen referencia a la misma entidad (Aunque todos vieron al Presidente , ninguno reconocio\u0301 al ganador de las u\u0301ltimas elecciones )","title":"Retos NLP"},{"location":"asignaturas/primer_cuatrimestre/mineria_de_textos/1_procesamiento_lenguaje_natural/#evaluacion-de-tareas","text":"Es necesario obtener datos de evaluacio\u0301n de los modelos y sistemas para el avance del a\u0301rea. Es necesario comparar modelos y sistemas de formas justa: Sobre los mismos datos: corpus o colecciones comunes Usando las mismas medidas","title":"Evaluaci\u00f3n de Tareas"},{"location":"asignaturas/primer_cuatrimestre/mineria_de_textos/1_procesamiento_lenguaje_natural/#corpus","text":"Un corpus es una compilacio\u0301n de textos en formato electro\u0301nico. Son un recurso fundamental en el desarrollo de aplicaciones basadas en PLN: * Permiten evaluar los sistemas * Proporcionan un marco comu\u0301n para comparar te\u0301cnicas alternativas * Permiten entrenar los sistemas de aprendizaje automa\u0301tico supervisados: ajustan sus para\u0301metros a partir de una parte del corpus usada para entrenamiento. * Proporcionan una muestra amplia y natural del lenguaje. * Son una fuente de datos estadi\u0301sticos sobre las palabras, sus relaciones y sus construcciones.","title":"Corpus"},{"location":"asignaturas/primer_cuatrimestre/mineria_de_textos/1_procesamiento_lenguaje_natural/#aplicaciones","text":"Asignacio\u0301n automa\u0301tica de categori\u0301as le\u0301xicas Desambiguacio\u0301n sinta\u0301ctica Extraccio\u0301n de grama\u0301ticas Traduccio\u0301n automa\u0301tica Extraccio\u0301n de entidades (nombres, medicamentos, etc.) Extraccio\u0301n de relaciones","title":"Aplicaciones"},{"location":"asignaturas/primer_cuatrimestre/mineria_de_textos/1_procesamiento_lenguaje_natural/#tipos-generales","text":"Sin anotar: Texto puro Anotados: marcados con distintos tipos de informacio\u0301n lingu\u0308i\u0301stica (se les denomina Gold standard y se usan de referencia) Monolingu\u0308e: textos pertenecientes a una u\u0301nica lengua Multilingu\u0308e: textos en diversas lenguas. Proporcionan anotaciones similares en distintas lenguas Paralelo: contiene los mismos textos en ma\u0301s de una lengua Comparable: Contiene un nu\u0301mero equilibrado de textos en distintas lenguas. Tambie\u0301n esta\u0301n equilibrados respecto al tema y tipo de textos","title":"Tipos generales"},{"location":"asignaturas/primer_cuatrimestre/mineria_de_textos/1_procesamiento_lenguaje_natural/#ejemplos","text":"Corpus de Brown http://www.nltk.org/nltk_data Palabras anotadas (+1M) Categor\u00edas l\u00e9xicas 87 Etiquetas Corpus de Susanne http://www.nltk.org/nltk_data Palabras (+130K) Subconjunto de 64 archivos del corpus de Brown Anotado con categori\u0301as le\u0301xicas y ana\u0301lisis sinta\u0301ctico Por cada palabra de texto hay una li\u0301nea de anotaciones (ana\u0301lisis sinta\u0301ctico) Corpus ADE https://github.com/trunghlt/AdverseDrugReaction Relaciones entre efectos adversos y medicamentos Corpus Bioscope: http://rgai.inf.u-szeged.hu/index.php?lang=en&page=bioscope Textos biome\u0301dicos anotados con negacio\u0301n y especulacio\u0301n Corpus DDI: https://omictools.com/ddi-corpus-tool Anotacio\u0301n de medicamentos e interacciones entre ellos: The DDI corpus: an annotated corpus with pharmacological substances and drug-drug interactions. Corpus Europarl: http://www.statmt.org/europarl/ Actas del parlamento europeo en 21 lenguas de Europa: Espan\u0303ol, Ingle\u0301s, France\u0301s, Griego, ..., con alineamiento o correspondencia a nivel de oracio\u0301n) Corpus DIANN https://github.com/gildofabregat/DIANN-IBEREVAL-2018/tree/master/DIANN_CORPUS Discapacidades anotadas","title":"Ejemplos"},{"location":"asignaturas/primer_cuatrimestre/mineria_de_textos/1_procesamiento_lenguaje_natural/#evaluacion-de-tareas_1","text":"","title":"Evaluaci\u00f3n de Tareas"},{"location":"asignaturas/primer_cuatrimestre/mineria_de_textos/1_procesamiento_lenguaje_natural/#campanas-de-evaluacion","text":"Proponen retos a los participantes, proporcionando datos y un marco de evaluacio\u0301n comu\u0301n y bien definido. * TREC: Text Retrieval conference * CLEF: Conference and Labs of the evaluation Forum * Semeval: Semantic Evaluation Ibereval: Lenguas Ibe\u0301ricas","title":"Campan\u0303as de evaluacio\u0301n"},{"location":"asignaturas/primer_cuatrimestre/mineria_de_textos/1_procesamiento_lenguaje_natural/#medidas-de-evaluacion","text":"Precisio\u0301n : fraccio\u0301n de predicciones del modelo propuesto acertadas (coinciden con los datos de referencia) precission = true positive / (true positive + false positive) Recall : Cobertura o exhaustividad. Fraccio\u0301n de los datos de referencia que han sido propuestas por el modelo evaluado: recall = true positive / (true positive + false negative) Medida-F: media armo\u0301nica de precisio\u0301n y cobertura: meassure_f = 2 * precission * recall / (precission + recall) Medida-F\u03b2: forma general de la media armo\u0301nica que permite dar ma\u0301s importancia a la precisio\u0301n o a la cobertura en funcio\u0301n del para\u0301metro \u03b2: meassure_f_beta = ((1 + \u03b2^2) * precission * recall) / (\u03b2^2 * (precission + recall))","title":"Medidas de Evaluaci\u00f3n"},{"location":"asignaturas/primer_cuatrimestre/mineria_de_textos/1_procesamiento_lenguaje_natural/#ejemplo","text":"Tenemos: N\u00famero de datos totales: 16 N\u00famero de datos del modelo: 13 N\u00famero de datos que usa el modelo: 8 (true positive) N\u00famero de datos aportados: 11 Falsos negativos: 11 - 8 = 3 Falsos positivos: 13 - 8 = 5 Medidas: Precisi\u00f3n 8 / 8 + 5 = 8 / 13 Medida_F 8 / 8 + 3 = 8 / 11","title":"Ejemplo"},{"location":"asignaturas/primer_cuatrimestre/mineria_de_textos/1_procesamiento_lenguaje_natural/#herramientas","text":"Nltk: Natural Language Toolkit Libreri\u0301a para desarrollar programas en python para procesar datos de lenguaje natural https://www.nltk.org/ Ejemplos de como iniciarlo, y algunas de las utilidades ma\u0301s ba\u0301sicas: https://www.nltk.org/book/ch01.html Spacy: Libreri\u0301a para desarrollar programas en python para procesar datos de lenguaje natural https://spacy.io/ Tiene modelos preentrenados en Ingl\u00e9s y Espa\u00f1ol","title":"Herramientas"},{"location":"asignaturas/primer_cuatrimestre/mineria_de_textos/1_procesamiento_lenguaje_natural/#procesos","text":"Normalizacio\u0301n: Unificar palabras que se refieren de distinta forma a la misma entidad Expresiones regulares: Especificar patrones de texto Distancia de edicio\u0301n: Nu\u0301mero/coste de las operaciones de edicio\u0301n: Insercio\u0301n, Borrado, Sustitucio\u0301n Necesarias para transformar una cadena en la otra. Explorar todas las combinaciones de operacio\u0301n para seleccionar la de menor coste Importante para medir la similitud entre dos cadenas Se usan para correcci\u00f3n de errores ortogr\u00e1ficos, extracci\u00f3n de informaci\u00f3n... Identificar palabras vac\u00edas: Palabras sin significado propio: arti\u0301culos, preposiciones, etc. Suelen ser las ma\u0301s frecuentes en un idioma En muchos procesos de PLN se eliminan para centrar el ana\u0301lisis en las palabras con contenido sema\u0301ntico Segmentaci\u00f3n de cadenas: Romper una cadena de caracteres (grafemas) en una secuencia de palabras. POS tagging Part-Of-Speech Tagging: Etiquetar las palabras de una oracio\u0301n con su categori\u0301a le\u0301xica seg\u00fan su definici\u00f3n y el contexto de la oraci\u00f3n Cada palabra de una oracio\u0301n se puede clasificar en clases: verbos, adjetivos, nombres, etc \u00datil para: Identificacio\u0301n de entidades, desambiguacio\u0301n del sentido de las palabras, an\u00e1lisis sint\u00e1ctico... T\u00e9cnicas: Basados en reglas, modelo de probabilidades de las secuencias de palabras y sus etiquetas en funcio\u0301n de los datos de un corpus anotado, aprendizaje autom\u00e1tico. Evaluaci\u00f3n: Accuracy: nu\u0301mero de etiquetas acertadas sobre el nu\u0301mero total de palabras etiquetadas Precisio\u0301n, cobertura y medida-F para cada tipo de etiqueta del conjunto de etiquetas considerado Stemming An\u00e1lisis morfol\u00f3gico El proceso de stemming se refiere al proceso de eliminar la parte final de las palabras, que en muchas ocasiones es una aproximacio\u0301n a la lematizacio\u0301n. Permite reconocer todas las palabras correspondiente a una misma rai\u0301z Chunking Parte en trozos (chunks) y etiqueta secuencias multipalabra NP-chunks suelen ser menores que las frases nominales: NP-chunks no contienen otros NP-chunks Los sintagmas preposicionales o las cla\u0301usulas subordinadas que modifican un nominal no se suelen incluir. Se puede construir una gramatica de deteccio\u0301n de chunks usando expresiones regulares sobre las etiquetas POS. (pag. 265 libro nltk) Tambie\u0301n puede construirse con clasificadores entrenados. An\u00e1lisis Sint\u00e1ctico: Identificar la estructura sinta\u0301ctica de una oracio\u0301n. La estructura asignada depende del tipo de grama\u0301tica considerada. Dificultad: ambigu\u0308edad estructural \u2192 una oracio\u0301n puede tener mu\u0301ltiples a\u0301rboles de ana\u0301lisis respecto a una misma grama\u0301tica Desambiguacio\u0301n del sentido de las palabras Muchas palabras tiene ma\u0301s de un significado o sentido dependiendo del contexto en que se usan Muchas aplicaciones requieren seleccionar el sentido correcto: Word Sense Disambiguation (WSD). Relaciones entre sentidos: Sino\u0301nimos: distintas palabras con el mismo (o muy similar) significado Hipo\u0301nimo: un sentido es hipo\u0301nimo de otro si el primero es ma\u0301s especi\u0301fico (una subclase). Hipero\u0301nimo: un sentido es hipero\u0301nimo de otro si el primero es ma\u0301s general (superclase) Wordnet: una base de datos de relaciones le\u0301xicas","title":"Procesos"},{"location":"asignaturas/primer_cuatrimestre/mineria_de_textos/1_procesamiento_lenguaje_natural/#analisis-morfolologico","text":"La morfologi\u0301a es el campo de la lingu\u0308i\u0301stica que estudia la estructura de las palabras Un morfema es la unidad lingu\u0308i\u0301stica ma\u0301s pequen\u0303a que tiene significado sema\u0301ntico El ana\u0301lisis morfolo\u0301gico es la tarea de segmentar una palabra en sus morfemas","title":"Ana\u0301lisis morfololo\u0301gico"},{"location":"asignaturas/primer_cuatrimestre/mineria_de_textos/1_procesamiento_lenguaje_natural/ejercicios/","text":"Ejercicios - Procesamiento del Lenguaje Natural \u00b6","title":"Ejercicio 1"},{"location":"asignaturas/primer_cuatrimestre/mineria_de_textos/1_procesamiento_lenguaje_natural/ejercicios/#ejercicios-procesamiento-del-lenguaje-natural","text":"","title":"Ejercicios - Procesamiento del Lenguaje Natural"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/ejercicios_tema_1/","text":"Tema 1 - Ejercicios R \u00b6 Respuesta Dicot\u00f3mica \u00b6 z diferencia de dos proporciones \u00b6 # 1. Remove all objects from the current workspace rm(list=ls()) # 2. Read the data from the d_d_1.txt file data = read.table(\"d_d_1.txt\", header=T) attach(data) # Note: exp = x variable, rta = y variable data_table = table(-rta, exp); # 3. Assign the indices: values_variable_x1 = which(exp==1); values_variable_x2 = which(exp==2); values_variable_y1_x1=which(rta==1 & exp==1); values_variable_y1_x2=which(rta==1 & exp==2); # 4. Assign the samples length answer1_num_values = length(rta[values_variable_y1_x1]); answer2_num_values = length(rta[values_variable_y1_x2]); sample1_num_values = length(rta[values_variable_x1]); sample2_num_values = length(rta[values_variable_x2]); # 5. Assign the alpha value alpha=0.05 # 6. Calc proportions proportion_1 = answer1_num_values / sample1_num_values; proportion_2 = answer2_num_values / sample2_num_values; proportion_difference = proportion_1 - proportion_2; # 7. Calc probabilty success p = (answer1_num_values + answer2_num_values) / (sample1_num_values + sample2_num_values); # success q = 1 - probability_success; # fail # 8. Calc deviation variance1 = p * q / sample1_num_values; variance2 = p * q / sample2_num_values; deviation = sqrt(variance1 + variance2) # 9. Calc z z0 = pnorm(1 - alpha) z = proportion_difference / deviation p_value = 2 * (1 - pnorm(abs(z))) Exacta de Fisher \u00b6 Respuesta Continua \u00b6 t de Student \u00b6 ANOVA de un factor \u00b6 Respuesta Nominal \u00b6 \u03c72 de homogeneidad \u00b6 Respuesta Ordinal \u00b6 U d eMann-Whitney \u00b6 W de Wilcoxon \u00b6 H de Kruskal-Wallis \u00b6","title":"Ejercicios"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/ejercicios_tema_1/#tema-1-ejercicios-r","text":"","title":"Tema 1 - Ejercicios R"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/ejercicios_tema_1/#respuesta-dicotomica","text":"","title":"Respuesta Dicot\u00f3mica"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/ejercicios_tema_1/#z-diferencia-de-dos-proporciones","text":"# 1. Remove all objects from the current workspace rm(list=ls()) # 2. Read the data from the d_d_1.txt file data = read.table(\"d_d_1.txt\", header=T) attach(data) # Note: exp = x variable, rta = y variable data_table = table(-rta, exp); # 3. Assign the indices: values_variable_x1 = which(exp==1); values_variable_x2 = which(exp==2); values_variable_y1_x1=which(rta==1 & exp==1); values_variable_y1_x2=which(rta==1 & exp==2); # 4. Assign the samples length answer1_num_values = length(rta[values_variable_y1_x1]); answer2_num_values = length(rta[values_variable_y1_x2]); sample1_num_values = length(rta[values_variable_x1]); sample2_num_values = length(rta[values_variable_x2]); # 5. Assign the alpha value alpha=0.05 # 6. Calc proportions proportion_1 = answer1_num_values / sample1_num_values; proportion_2 = answer2_num_values / sample2_num_values; proportion_difference = proportion_1 - proportion_2; # 7. Calc probabilty success p = (answer1_num_values + answer2_num_values) / (sample1_num_values + sample2_num_values); # success q = 1 - probability_success; # fail # 8. Calc deviation variance1 = p * q / sample1_num_values; variance2 = p * q / sample2_num_values; deviation = sqrt(variance1 + variance2) # 9. Calc z z0 = pnorm(1 - alpha) z = proportion_difference / deviation p_value = 2 * (1 - pnorm(abs(z)))","title":"z diferencia de dos proporciones"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/ejercicios_tema_1/#exacta-de-fisher","text":"","title":"Exacta de Fisher"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/ejercicios_tema_1/#respuesta-continua","text":"","title":"Respuesta Continua"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/ejercicios_tema_1/#t-de-student","text":"","title":"t de Student"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/ejercicios_tema_1/#anova-de-un-factor","text":"","title":"ANOVA de un factor"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/ejercicios_tema_1/#respuesta-nominal","text":"","title":"Respuesta Nominal"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/ejercicios_tema_1/#2-de-homogeneidad","text":"","title":"\u03c72 de homogeneidad"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/ejercicios_tema_1/#respuesta-ordinal","text":"","title":"Respuesta Ordinal"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/ejercicios_tema_1/#u-d-emann-whitney","text":"","title":"U d eMann-Whitney"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/ejercicios_tema_1/#w-de-wilcoxon","text":"","title":"W de Wilcoxon"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/ejercicios_tema_1/#h-de-kruskal-wallis","text":"","title":"H de Kruskal-Wallis"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/ejercicios_tema_2/","text":"","title":"Ejercicios"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/ejercicios_tema_3/","text":"","title":"Ejercicios"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/ejercicios_tema_4/","text":"","title":"Ejercicios"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/tema_1/","text":"Tema 1 - Principales T\u00e9cnicas Estad\u00edsticas \u00b6 Introducci\u00f3n \u00b6 Distribuciones Te\u00f3ricas de Probabilidad \u00b6 Distribuci\u00f3n: reparto de elementos / individuos de un grupo / poblaci\u00f3n seg\u00fan una caracter\u00edstica Ejemplo: Distribuci\u00f3n de caramelos con az\u00facar y sin az\u00facar en una bolsa de caramelos. Tenemos una bolsa de caramelos donde hay una mezcla de caramelos con az\u00facar y caramelos sin az\u00facar. Si existe el mismo n\u00famero de caramelos con y sin az\u00facar, dir\u00edamos que es una distribuci\u00f3n uniforme . La probabilidad de sacar un caramelo sin az\u00facar de la bolsa es 0,5. Distribuci\u00f3n de Frecuencias vs Distribuci\u00f3n de Probabilidad \u00b6 Distribuci\u00f3n de Frecuencias: Reparto emp\u00edrico (emp\u00edrico = basado en la observaci\u00f3n) observado en una colecci\u00f3n de datos. Agrupaci\u00f3n de datos en categor\u00edas mutuamente excluyentes (caramelos con o sin az\u00facar) que indican el n\u00famero de observaciones en cada categor\u00eda. Distribuci\u00f3n de Probabilidad: Reparto te\u00f3rico de la poblaci\u00f3n, una funci\u00f3n matem\u00e1tica. La distribuci\u00f3n de probabilidad est\u00e1 definida sobre el conjunto de todos los sucesos, y cada uno de los sucesos es el rango de valores de la variable aleatoria . Describe c\u00f3mo se espera que var\u00eden los resultados. Variable Aleatoria: Funci\u00f3n que asigna un valor, usualmente num\u00e9rico, al resultado de un experimento aleatorio, lo que quiere decir que son los resultados que se presentan al azar en cualquier evento o experimento. Por ejemplo, los posibles resultados de sacar tres caramelos de la bolsa de caramelos. Ejemplo: Conjunto de Datos: Bolsa con N caramelos (donde N puede ser cualquier n\u00famero de caramelos) donde hay dos tipos de caramelos: con y sin az\u00facar. Variable Aleatoria: sacar tres caramelos de la bolsa de caramelos Posibles resultados: [con, sin, sin], [sin, con, sin], [sin, sin , sin]... Tipos de Variables Aleatorias \u00b6 Variable aleatoria discreta: Es aquella que solo toma ciertos valores y que resulta principalmente del conteo realizado. Por ejemplo, que los caramelos sean con o sin az\u00facar. Variable aleatoria continua: Es aquella que resulta generalmente de la medici\u00f3n y puede tomar cualquier valor dentro de un intervalo dado. Por ejemplo, si nuestra bolsa de caramelos contiene caramelos redondos que pueden tener tama\u00f1os distintos, desde ser una bolita \"peque\u00f1a\" hasta una bolita \"grande\", pasando por todos los tama\u00f1os intermedios. Conceptos b\u00e1sicos: Varianza : Desviaci\u00f3n T\u00edpica : La desviaci\u00f3n t\u00edpica o est\u00e1ndar es una medida que ofrece informaci\u00f3n sobre la dispersi\u00f3n media de una variable. La desviaci\u00f3n t\u00edpica es siempre mayor o igual que cero. Esperanza matem\u00e1tica, valor esperado o media: Es la media de nuestra serie de datos. Desviaci\u00f3n: La desviaci\u00f3n es la separaci\u00f3n que existe entre un valor cualquiera de la serie y la media. Covarianza : valor que indica el grado de variaci\u00f3n conjunta de dos variables aleatorias respecto a sus medias. Cuando los valores altos de una de las variables suelen mayoritariamente corresponderse con los valores altos de la otra, y lo mismo se verifica para los peque\u00f1os valores de una con los de la otra, se corrobora que tienden a mostrar comportamiento similar lo que se refleja en un valor positivo de la covarianza Por el contrario, cuando a los mayores valores de una variable suelen corresponder en general los menores de la otra, expresando un comportamiento opuesto, la covarianza es negativa. El signo de la covarianza, por lo tanto, expresa la tendencia en la relaci\u00f3n lineal entre las variables. cov(X, Y) = E[(X - E[X])(Y - E[Y])] (Nota: E[X] = Valor esperado de X, o la media de X.) El Teorema Central del L\u00edmite \u00b6 Este m\u00e9todo se utiliza con tama\u00f1os de muestra grandes . Es decir, en el ejemplo anterior, tener pocos pececillos enfermos no es suficiente para conocer cu\u00e1l es el tratamiento adecuado para que se curen los pobrecillos. Si tenemos muchos peces, el resultado ser\u00e1 m\u00e1s fiable, y esto lo conocemos gracias al Teorema Central del L\u00edmite . Teorema Central del L\u00edmite : Indica que, en condiciones muy generales, dada la suma de n variables aleatorias independientes y cuya dispersi\u00f3n se puede cuantificar, la funci\u00f3n de distribuci\u00f3n de S(n) \u00abse aproxima bien\u00bb a una distribuci\u00f3n normal (tambi\u00e9n llamada distribuci\u00f3n gaussiana, curva de Gauss o campana de Gauss). Distribuci\u00f3n Normal : Esta distribuci\u00f3n es muy utilizada en estad\u00edstica ya que permite representar numerosos fen\u00f3menos, como por ejemplo, el de los pececillos mutates, pero tambi\u00e9n muchos otros de caracteres naturales, sociales, psicol\u00f3gicos, etc. La distribuci\u00f3n normal se basa en la justificaci\u00f3n de que una observaci\u00f3n, o resultado final, se puede obtener como la suma de causas peque\u00f1as independientes . La distribuci\u00f3n normal es la m\u00e1s extendida en estad\u00edstica y muchos tests estad\u00edsticos est\u00e1n basados en una \"normalidad\" m\u00e1s o menos justificada de la variable aleatoria bajo estudio. Pruebas de hip\u00f3tesis \u00b6 Este v\u00eddeo es \u00fatil para comprender en qu\u00e9 consiste una prueba de hip\u00f3tesis: Tipos de variables \u00b6 Dicot\u00f3mica: puede ser un valor o su contrario, pero no los dos a la vez. Continua: puede tomar distintos valores entre un rango de valores Nominal: Ordinal: Bibliograf\u00eda \u00b6 Pruebas de Hip\u00f3tesis para la diferencia de Medias P\u00edldoras Matem\u00e1ticas - La Distribuci\u00f3n Normal P\u00edldoras Matem\u00e1ticas - Probabilidad P\u00edldoras Matem\u00e1ticas - La Distribuci\u00f3n Binomial El test z para comparar dos proporciones (umh2072 2013-14) Distribuci\u00f3n Normal - Wikipedia MaximaFormacion - Diferencias entre las proporciones de 2 poblaciones diferentes Prueba hip\u00f3tesis z diferencia de dos proporciones Apuntes Prueba exacta de Fisher Grados de Libertad - t de Student Test de t de Student - Diferencia de Medias","title":"Introducci\u00f3n"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/tema_1/#tema-1-principales-tecnicas-estadisticas","text":"","title":"Tema 1 - Principales T\u00e9cnicas Estad\u00edsticas"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/tema_1/#introduccion","text":"","title":"Introducci\u00f3n"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/tema_1/#distribuciones-teoricas-de-probabilidad","text":"Distribuci\u00f3n: reparto de elementos / individuos de un grupo / poblaci\u00f3n seg\u00fan una caracter\u00edstica Ejemplo: Distribuci\u00f3n de caramelos con az\u00facar y sin az\u00facar en una bolsa de caramelos. Tenemos una bolsa de caramelos donde hay una mezcla de caramelos con az\u00facar y caramelos sin az\u00facar. Si existe el mismo n\u00famero de caramelos con y sin az\u00facar, dir\u00edamos que es una distribuci\u00f3n uniforme . La probabilidad de sacar un caramelo sin az\u00facar de la bolsa es 0,5.","title":"Distribuciones Te\u00f3ricas de Probabilidad"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/tema_1/#distribucion-de-frecuencias-vs-distribucion-de-probabilidad","text":"Distribuci\u00f3n de Frecuencias: Reparto emp\u00edrico (emp\u00edrico = basado en la observaci\u00f3n) observado en una colecci\u00f3n de datos. Agrupaci\u00f3n de datos en categor\u00edas mutuamente excluyentes (caramelos con o sin az\u00facar) que indican el n\u00famero de observaciones en cada categor\u00eda. Distribuci\u00f3n de Probabilidad: Reparto te\u00f3rico de la poblaci\u00f3n, una funci\u00f3n matem\u00e1tica. La distribuci\u00f3n de probabilidad est\u00e1 definida sobre el conjunto de todos los sucesos, y cada uno de los sucesos es el rango de valores de la variable aleatoria . Describe c\u00f3mo se espera que var\u00eden los resultados. Variable Aleatoria: Funci\u00f3n que asigna un valor, usualmente num\u00e9rico, al resultado de un experimento aleatorio, lo que quiere decir que son los resultados que se presentan al azar en cualquier evento o experimento. Por ejemplo, los posibles resultados de sacar tres caramelos de la bolsa de caramelos. Ejemplo: Conjunto de Datos: Bolsa con N caramelos (donde N puede ser cualquier n\u00famero de caramelos) donde hay dos tipos de caramelos: con y sin az\u00facar. Variable Aleatoria: sacar tres caramelos de la bolsa de caramelos Posibles resultados: [con, sin, sin], [sin, con, sin], [sin, sin , sin]...","title":"Distribuci\u00f3n de Frecuencias vs Distribuci\u00f3n de Probabilidad"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/tema_1/#tipos-de-variables-aleatorias","text":"Variable aleatoria discreta: Es aquella que solo toma ciertos valores y que resulta principalmente del conteo realizado. Por ejemplo, que los caramelos sean con o sin az\u00facar. Variable aleatoria continua: Es aquella que resulta generalmente de la medici\u00f3n y puede tomar cualquier valor dentro de un intervalo dado. Por ejemplo, si nuestra bolsa de caramelos contiene caramelos redondos que pueden tener tama\u00f1os distintos, desde ser una bolita \"peque\u00f1a\" hasta una bolita \"grande\", pasando por todos los tama\u00f1os intermedios. Conceptos b\u00e1sicos: Varianza : Desviaci\u00f3n T\u00edpica : La desviaci\u00f3n t\u00edpica o est\u00e1ndar es una medida que ofrece informaci\u00f3n sobre la dispersi\u00f3n media de una variable. La desviaci\u00f3n t\u00edpica es siempre mayor o igual que cero. Esperanza matem\u00e1tica, valor esperado o media: Es la media de nuestra serie de datos. Desviaci\u00f3n: La desviaci\u00f3n es la separaci\u00f3n que existe entre un valor cualquiera de la serie y la media. Covarianza : valor que indica el grado de variaci\u00f3n conjunta de dos variables aleatorias respecto a sus medias. Cuando los valores altos de una de las variables suelen mayoritariamente corresponderse con los valores altos de la otra, y lo mismo se verifica para los peque\u00f1os valores de una con los de la otra, se corrobora que tienden a mostrar comportamiento similar lo que se refleja en un valor positivo de la covarianza Por el contrario, cuando a los mayores valores de una variable suelen corresponder en general los menores de la otra, expresando un comportamiento opuesto, la covarianza es negativa. El signo de la covarianza, por lo tanto, expresa la tendencia en la relaci\u00f3n lineal entre las variables. cov(X, Y) = E[(X - E[X])(Y - E[Y])] (Nota: E[X] = Valor esperado de X, o la media de X.)","title":"Tipos de Variables Aleatorias"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/tema_1/#el-teorema-central-del-limite","text":"Este m\u00e9todo se utiliza con tama\u00f1os de muestra grandes . Es decir, en el ejemplo anterior, tener pocos pececillos enfermos no es suficiente para conocer cu\u00e1l es el tratamiento adecuado para que se curen los pobrecillos. Si tenemos muchos peces, el resultado ser\u00e1 m\u00e1s fiable, y esto lo conocemos gracias al Teorema Central del L\u00edmite . Teorema Central del L\u00edmite : Indica que, en condiciones muy generales, dada la suma de n variables aleatorias independientes y cuya dispersi\u00f3n se puede cuantificar, la funci\u00f3n de distribuci\u00f3n de S(n) \u00abse aproxima bien\u00bb a una distribuci\u00f3n normal (tambi\u00e9n llamada distribuci\u00f3n gaussiana, curva de Gauss o campana de Gauss). Distribuci\u00f3n Normal : Esta distribuci\u00f3n es muy utilizada en estad\u00edstica ya que permite representar numerosos fen\u00f3menos, como por ejemplo, el de los pececillos mutates, pero tambi\u00e9n muchos otros de caracteres naturales, sociales, psicol\u00f3gicos, etc. La distribuci\u00f3n normal se basa en la justificaci\u00f3n de que una observaci\u00f3n, o resultado final, se puede obtener como la suma de causas peque\u00f1as independientes . La distribuci\u00f3n normal es la m\u00e1s extendida en estad\u00edstica y muchos tests estad\u00edsticos est\u00e1n basados en una \"normalidad\" m\u00e1s o menos justificada de la variable aleatoria bajo estudio.","title":"El Teorema Central del L\u00edmite"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/tema_1/#pruebas-de-hipotesis","text":"Este v\u00eddeo es \u00fatil para comprender en qu\u00e9 consiste una prueba de hip\u00f3tesis:","title":"Pruebas de hip\u00f3tesis"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/tema_1/#tipos-de-variables","text":"Dicot\u00f3mica: puede ser un valor o su contrario, pero no los dos a la vez. Continua: puede tomar distintos valores entre un rango de valores Nominal: Ordinal:","title":"Tipos de variables"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/tema_1/#bibliografia","text":"Pruebas de Hip\u00f3tesis para la diferencia de Medias P\u00edldoras Matem\u00e1ticas - La Distribuci\u00f3n Normal P\u00edldoras Matem\u00e1ticas - Probabilidad P\u00edldoras Matem\u00e1ticas - La Distribuci\u00f3n Binomial El test z para comparar dos proporciones (umh2072 2013-14) Distribuci\u00f3n Normal - Wikipedia MaximaFormacion - Diferencias entre las proporciones de 2 poblaciones diferentes Prueba hip\u00f3tesis z diferencia de dos proporciones Apuntes Prueba exacta de Fisher Grados de Libertad - t de Student Test de t de Student - Diferencia de Medias","title":"Bibliograf\u00eda"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/tema_1/respuesta_continua/","text":"Introducci\u00f3n \u00b6 Vamos a ver dos maneras de obtener una variable respuesta continua : A trav\u00e9s de una variable explicativa dicot\u00f3mica : t de Student A trav\u00e9s de una variable explicativa nominal : An\u00e1lisis de la varianza (ANOVA) Grados de libertad \u00b6 Definiciones: \u201cEl valor de los grados de libertad se relaciona con el n\u00famero de veces que se usa la informaci\u00f3n de la muestra\u201d. \u201cSe definen como el n\u00famero de valores que podemos escoger libremente \u201d. \u201cLos grados de libertad de una prueba estad\u00edstica son el n\u00famero de datos que son libres de variar cuando se calcula tal prueba\u201d. Lectura recomendada: Grados de Libertad Homocedasticidad y heterocedasticidad \u00b6 En estad\u00edstica se dice que un modelo predictivo presenta homocedasticidad cuando la varianza del error condicional a las variables explicativas es constante en todas las observaciones realizadas. La homocedasticidad es una propiedad fundamental del modelo de regresi\u00f3n lineal general y est\u00e1 dentro de sus supuestos cl\u00e1sicos b\u00e1sicos. En estad\u00edstica se dice que un modelo de regresi\u00f3n lineal presenta heterocedasticidad cuandola varianza del error condicional no es constante en todas las observaciones realizadas. En el contraste de hip\u00f3tesis, hay que considerar tambi\u00e9n los supuestos de homocedasticidad y heterocedasticidad. M\u00e9todo 1: t de Student \u00b6 Intenta explicar la variable respuesta continua a trav\u00e9s de la variable explicativa dicot\u00f3mica. La variable respuesta es una variable que puede tomar valores continuos. Met\u00e1fora de los Peces Mutantes Imaginemos a nuestros pobres pececillos del lago. Ahora, en lugar de estar curados o no en base a un tratamiento, digamos que estos peces tienen un gen mutante . Este gen mutante puede adquirir multitud de valores, pero estos valores pueden depender del tratamiento que se le suministre al pez. Como estamos probando dos tratamientos, queremos conocer qu\u00e9 tratamiento produce seg\u00fan qu\u00e9 valores del gen. La distribuci\u00f3n t o t de Student es una distribuci\u00f3n de probabilidad que surge del problema de estimar la media de una poblaci\u00f3n normalmente distribuida cuando el tama\u00f1o de muestra es peque\u00f1o . Para usar este m\u00e9todo, tenemos que saber cu\u00e1l es el Grado de Libertad que vamos a manejar. En este m\u00e9todo, sabemos cu\u00e1l es la probabilidad de que una variable con \u03bd grados de libertad sea mayor que una variable t, y tenemos que calcular el valor de la variable t. Los grados de libertad y el nivel de confianza \u03b1 nos sirven para calcular el valor de t que queremos comparar en la tabla . (\u03bd = grado de libertad) \u03bd 0,6 0,75 0,9 0,95 0,975 0,99 0,995 0,9975 0,999 0,9995 ---+---------------------------------------------------------------------- 1 | 0,325 1,000 3,078 6,314 12,706 31,821 63,656 127,321 318,289 636,578 2 | 0,289 0,816 1,886 2,920 4,303 6,965 9,925 14,089 22,328 31,600 3 | 0,277 0,765 1,638 2,353 3,182 4,541 5,841 7,453 10,214 12,924 4 | 0,271 0,741 1,533 2,132 2,776 3,747 4,604 5,598 7,173 8,610 5 | 0,267 0,727 1,476 2,015 2,571 3,365 4,032 4,773 5,894 6,869 6 | 0,265 0,718 1,440 1,943 2,447 3,143 3,707 4,317 5,208 5,959 7 | 0,263 0,711 1,415 1,895 2,365 2,998 3,499 4,029 4,785 5,408 8 | 0,262 0,706 1,397 1,860 2,306 2,896 3,355 3,833 4,501 5,041 9 | 0,261 0,703 1,383 1,833 2,262 2,821 3,250 3,690 4,297 4,781 10 | 0,260 0,700 1,372 1,812 2,228 2,764 3,169 3,581 4,144 4,587 11 | 0,260 0,697 1,363 1,796 2,201 2,718 3,106 3,497 4,025 4,437 12 | 0,259 0,695 1,356 1,782 2,179 2,681 3,055 3,428 3,930 4,318 13 | 0,259 0,694 1,350 1,771 2,160 2,650 3,012 3,372 3,852 4,221 14 | 0,258 0,692 1,345 1,761 2,145 2,624 2,977 3,326 3,787 4,140 15 | 0,258 0,691 1,341 1,753 2,131 2,602 2,947 3,286 3,733 4,073 16 | 0,258 0,690 1,337 1,746 2,120 2,583 2,921 3,252 3,686 4,015 17 | 0,257 0,689 1,333 1,740 2,110 2,567 2,898 3,222 3,646 3,965 18 | 0,257 0,688 1,330 1,734 2,101 2,552 2,878 3,197 3,610 3,922 19 | 0,257 0,688 1,328 1,729 2,093 2,539 2,861 3,174 3,579 3,883 20 | 0,257 0,687 1,325 1,725 2,086 2,528 2,845 3,153 3,552 3,850 21 | 0,257 0,686 1,323 1,721 2,080 2,518 2,831 3,135 3,527 3,819 22 | 0,256 0,686 1,321 1,717 2,074 2,508 2,819 3,119 3,505 3,792 23 | 0,256 0,685 1,319 1,714 2,069 2,500 2,807 3,104 3,485 3,768 24 | 0,256 0,685 1,318 1,711 2,064 2,492 2,797 3,091 3,467 3,745 25 | 0,256 0,684 1,316 1,708 2,060 2,485 2,787 3,078 3,450 3,725 26 | 0,256 0,684 1,315 1,706 2,056 2,479 2,779 3,067 3,435 3,707 27 | 0,256 0,684 1,314 1,703 2,052 2,473 2,771 3,057 3,421 3,689 28 | 0,256 0,683 1,313 1,701 2,048 2,467 2,763 3,047 3,408 3,674 29 | 0,256 0,683 1,311 1,699 2,045 2,462 2,756 3,038 3,396 3,660 30 | 0,256 0,683 1,310 1,697 2,042 2,457 2,750 3,030 3,385 3,646 40 | 0,255 0,681 1,303 1,684 2,021 2,423 2,704 2,971 3,307 3,551 60 | 0,254 0,679 1,296 1,671 2,000 2,390 2,660 2,915 3,232 3,460 120| 0,254 0,677 1,289 1,658 1,980 2,358 2,617 2,860 3,160 3,373 \u221e | 0,253 0,674 1,282 1,645 1,960 2,326 2,576 2,807 3,090 3,290 De nuestro enorme lago de peces, vamos a tomar dos muestras (las muestras son aleatorias e independientes ): - A la muestra 1, formada por n1 peces, se le ha suministrado el tratamiento 1 - A la muestra 2, formada por n2 peces, se le ha suministrado el tratamiento 2 Por lo tanto, el n\u00famero total de peces que hemos tratado ser\u00e1 n = n1 + n2 . Para saber si el tipo del tratamiento influye en el gen mutante , vamos a comparar las medias de ambas muestras, tenemos que ver cu\u00e1l de los siguientes casos ocurre: si hay o no hay diferencia significativa comparando los intervalos de confianza: Leyenda * \u03bc = media de la muestra * |-------- \u03bc --------| = Intervalo de Confianza * s = Cuasivarianza * \u03b1 = nivel de confianza Caso 1: No hay diferencia significativa |-------- \u03bc1 --------| |-------- \u03bc2 --------| Caso 2: S\u00ed hay diferencia significativa |-------- \u03bc1 --------| |-------- \u03bc2 --------| Plantearemos, lo primero, las hip\u00f3tesis, siendo H0 la hip\u00f3tesis nula: H0: \u03bc1 - \u03bc1 = 0 H1: \u03bc1 - \u03bc1 != 0 Despu\u00e9s, hay que considerar los casos de homocedasticidad y heterocedasticidad Homocedasticidad : Cuando la varianza del error condicional es constante: Nota : s es la varianza de una de las muestras Calcular t t = \u03bc1 - \u03bc1 / sqrt( s * (1/n1 + 1/n2)) Buscar el valor de t en la tabla para la confianza \u03b1 y con n1 + n2 \u2212 2 grados de libertad t_ = (1 \u2212 \u03b1) / 2, n1 + n2 \u2212 2 Comparar |t| > t_ heterocedasticidad : Cuando la varianza del error condicional no es constante: Nota : s1 es la varianza de la muestra 1 y s2 es la varianza de la muestra 2 Calcular t t = \u03bc1 - \u03bc1 / sqrt( s1/n1 + s2/n2) Buscar el valor de t en la tabla para la confianza \u03b1 y con n1 + n2 \u2212 2 grados de libertad t_ = (1 \u2212 \u03b1) / 2, n1 + n2 \u2212 2 Comparar |t| > t_ M\u00e9todo 2: An\u00e1lisis de la Varianza \u00b6 Este an\u00e1lisis permite averiguar si el resultado de un experimento es significativo, es decir: saber si hay que descartar la hip\u00f3tesis nula o aceptar la hip\u00f3tesis alternativa. Est\u00e1 indicado para variables y normales con igual varianza (homocedasticidad). Usamos ANOVA de un factor cuando queremos saber si las medias de una variable son diferentes entre los niveles o grupos de otra variable. Condiciones: En ANOVA de un factor solo se relacionan dos variables: una variable dependiente (o a explicar) y una variable independiente (que en esta t\u00e9cnica se suele llamar factor) La variable dependiente es cuantitativa (escalar) y la variable independiente es categ\u00f3rica (nominal u ordinal). Se pide que las variables sigan la distribuci\u00f3n normal, aunque como siempre esto es dif\u00edcil de cumplir en investigaciones sociales. Tambi\u00e9n que las varianzas (es decir, las desviaciones t\u00edpicas al cuadrado) de cada grupo de la variable independiente sean similiares (homocedasticidad). Aunque esto es lo ideal, en la realidad cuesta de cumplir, e igualmente se puede aplicar ANOVA El estad\u00edstico F o F-test (se llama F en honor al estad\u00edstico Ronald Fisher) se obtiene al estimar la variaci\u00f3n de las medias entre los grupos de la variable independiente y dividirla por la estimaci\u00f3n de la variaci\u00f3n de las medias dentro de los grupos. Si hacemos varios an\u00e1lisis de ANOVA de un factor, aquel con F m\u00e1s alto indicar\u00e1 que hay m\u00e1s diferencias y por tanto una relaci\u00f3n m\u00e1s fuerte entre las variables. Cuanto m\u00e1s difieren las medias de la variable dependiente entre los grupos de la variable independiente, m\u00e1s alto ser\u00e1 el valor de F. Met\u00e1fora de los Peces Mutantes Vamos a suponer que tenemos tres lagos de peces mutantes. Debido a la mutaci\u00f3n, los peces pueden tener n\u00fameros distintos de ojos (en concreto, de 1 a 10 ojos). En cada lago hay un tipo de mutaci\u00f3n distinta, y queremos saber c\u00f3mo influye el tipo de mutaci\u00f3n en el n\u00famero de ojos de los peces mutantes. Se establece una variable explicativa que, ser\u00e1 el n\u00famero de ojos por pez. En este caso, dir\u00edamos que la hip\u00f3tesis nula es que la media de ojos es la misma en los tres lagos y que, por lo tanto, no influye el tipo de mutaci\u00f3n en el n\u00famero de ojos de los peces mutantes. La hip\u00f3tesis alternativa es que la media de ojos es distinta y s\u00ed que influye. Valores necesarios: media de las tres muestras: m media de cada una de las muestras: m1 , m2 ... m_n n\u00famero total de valores: n n\u00famero de valores de cada muestra: n1 , n2 ... n_n n\u00famero de muestras: r Creamos la tabla ANOVA, donde SCE: Suma de Cuadrados de la variable Explicativa SCE = n1(m1 - m)^2 + n2(m2 - m)^2 + .. + n_n(m_n - m)^2 SCR: Suma de Cuadrados de la variable Residual SCR = (m1 - m)^2 + (m2 - m)^2 + .. + (m_n - m)^2 SCT: Suma de Cuadrados Total = SCE + SCR GLE: Grados de Libertad de la parte Explicativa = r \u2212 1 GLR: Grados de Libertad de la parte Residual = n \u2212 r GLT: Grados de Libertad Totales = GLE + GLR CME: Cuadrado Medio Explicado = SCE / GLE CMR: Cuadrado Medio Residual = SCR / GLR F = CME / CMR CMT: Cuadrado Medio Total Suma Cuadrados Cuadrados Medios Grados Libertad F p - valor Explicativa SCE CME GLE F p - valor Residual SCR CMR GLR Total SCT CMT GLT","title":"Respuesta Continua"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/tema_1/respuesta_continua/#introduccion","text":"Vamos a ver dos maneras de obtener una variable respuesta continua : A trav\u00e9s de una variable explicativa dicot\u00f3mica : t de Student A trav\u00e9s de una variable explicativa nominal : An\u00e1lisis de la varianza (ANOVA)","title":"Introducci\u00f3n"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/tema_1/respuesta_continua/#grados-de-libertad","text":"Definiciones: \u201cEl valor de los grados de libertad se relaciona con el n\u00famero de veces que se usa la informaci\u00f3n de la muestra\u201d. \u201cSe definen como el n\u00famero de valores que podemos escoger libremente \u201d. \u201cLos grados de libertad de una prueba estad\u00edstica son el n\u00famero de datos que son libres de variar cuando se calcula tal prueba\u201d. Lectura recomendada: Grados de Libertad","title":"Grados de libertad"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/tema_1/respuesta_continua/#homocedasticidad-y-heterocedasticidad","text":"En estad\u00edstica se dice que un modelo predictivo presenta homocedasticidad cuando la varianza del error condicional a las variables explicativas es constante en todas las observaciones realizadas. La homocedasticidad es una propiedad fundamental del modelo de regresi\u00f3n lineal general y est\u00e1 dentro de sus supuestos cl\u00e1sicos b\u00e1sicos. En estad\u00edstica se dice que un modelo de regresi\u00f3n lineal presenta heterocedasticidad cuandola varianza del error condicional no es constante en todas las observaciones realizadas. En el contraste de hip\u00f3tesis, hay que considerar tambi\u00e9n los supuestos de homocedasticidad y heterocedasticidad.","title":"Homocedasticidad y heterocedasticidad"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/tema_1/respuesta_continua/#metodo-1-t-de-student","text":"Intenta explicar la variable respuesta continua a trav\u00e9s de la variable explicativa dicot\u00f3mica. La variable respuesta es una variable que puede tomar valores continuos. Met\u00e1fora de los Peces Mutantes Imaginemos a nuestros pobres pececillos del lago. Ahora, en lugar de estar curados o no en base a un tratamiento, digamos que estos peces tienen un gen mutante . Este gen mutante puede adquirir multitud de valores, pero estos valores pueden depender del tratamiento que se le suministre al pez. Como estamos probando dos tratamientos, queremos conocer qu\u00e9 tratamiento produce seg\u00fan qu\u00e9 valores del gen. La distribuci\u00f3n t o t de Student es una distribuci\u00f3n de probabilidad que surge del problema de estimar la media de una poblaci\u00f3n normalmente distribuida cuando el tama\u00f1o de muestra es peque\u00f1o . Para usar este m\u00e9todo, tenemos que saber cu\u00e1l es el Grado de Libertad que vamos a manejar. En este m\u00e9todo, sabemos cu\u00e1l es la probabilidad de que una variable con \u03bd grados de libertad sea mayor que una variable t, y tenemos que calcular el valor de la variable t. Los grados de libertad y el nivel de confianza \u03b1 nos sirven para calcular el valor de t que queremos comparar en la tabla . (\u03bd = grado de libertad) \u03bd 0,6 0,75 0,9 0,95 0,975 0,99 0,995 0,9975 0,999 0,9995 ---+---------------------------------------------------------------------- 1 | 0,325 1,000 3,078 6,314 12,706 31,821 63,656 127,321 318,289 636,578 2 | 0,289 0,816 1,886 2,920 4,303 6,965 9,925 14,089 22,328 31,600 3 | 0,277 0,765 1,638 2,353 3,182 4,541 5,841 7,453 10,214 12,924 4 | 0,271 0,741 1,533 2,132 2,776 3,747 4,604 5,598 7,173 8,610 5 | 0,267 0,727 1,476 2,015 2,571 3,365 4,032 4,773 5,894 6,869 6 | 0,265 0,718 1,440 1,943 2,447 3,143 3,707 4,317 5,208 5,959 7 | 0,263 0,711 1,415 1,895 2,365 2,998 3,499 4,029 4,785 5,408 8 | 0,262 0,706 1,397 1,860 2,306 2,896 3,355 3,833 4,501 5,041 9 | 0,261 0,703 1,383 1,833 2,262 2,821 3,250 3,690 4,297 4,781 10 | 0,260 0,700 1,372 1,812 2,228 2,764 3,169 3,581 4,144 4,587 11 | 0,260 0,697 1,363 1,796 2,201 2,718 3,106 3,497 4,025 4,437 12 | 0,259 0,695 1,356 1,782 2,179 2,681 3,055 3,428 3,930 4,318 13 | 0,259 0,694 1,350 1,771 2,160 2,650 3,012 3,372 3,852 4,221 14 | 0,258 0,692 1,345 1,761 2,145 2,624 2,977 3,326 3,787 4,140 15 | 0,258 0,691 1,341 1,753 2,131 2,602 2,947 3,286 3,733 4,073 16 | 0,258 0,690 1,337 1,746 2,120 2,583 2,921 3,252 3,686 4,015 17 | 0,257 0,689 1,333 1,740 2,110 2,567 2,898 3,222 3,646 3,965 18 | 0,257 0,688 1,330 1,734 2,101 2,552 2,878 3,197 3,610 3,922 19 | 0,257 0,688 1,328 1,729 2,093 2,539 2,861 3,174 3,579 3,883 20 | 0,257 0,687 1,325 1,725 2,086 2,528 2,845 3,153 3,552 3,850 21 | 0,257 0,686 1,323 1,721 2,080 2,518 2,831 3,135 3,527 3,819 22 | 0,256 0,686 1,321 1,717 2,074 2,508 2,819 3,119 3,505 3,792 23 | 0,256 0,685 1,319 1,714 2,069 2,500 2,807 3,104 3,485 3,768 24 | 0,256 0,685 1,318 1,711 2,064 2,492 2,797 3,091 3,467 3,745 25 | 0,256 0,684 1,316 1,708 2,060 2,485 2,787 3,078 3,450 3,725 26 | 0,256 0,684 1,315 1,706 2,056 2,479 2,779 3,067 3,435 3,707 27 | 0,256 0,684 1,314 1,703 2,052 2,473 2,771 3,057 3,421 3,689 28 | 0,256 0,683 1,313 1,701 2,048 2,467 2,763 3,047 3,408 3,674 29 | 0,256 0,683 1,311 1,699 2,045 2,462 2,756 3,038 3,396 3,660 30 | 0,256 0,683 1,310 1,697 2,042 2,457 2,750 3,030 3,385 3,646 40 | 0,255 0,681 1,303 1,684 2,021 2,423 2,704 2,971 3,307 3,551 60 | 0,254 0,679 1,296 1,671 2,000 2,390 2,660 2,915 3,232 3,460 120| 0,254 0,677 1,289 1,658 1,980 2,358 2,617 2,860 3,160 3,373 \u221e | 0,253 0,674 1,282 1,645 1,960 2,326 2,576 2,807 3,090 3,290 De nuestro enorme lago de peces, vamos a tomar dos muestras (las muestras son aleatorias e independientes ): - A la muestra 1, formada por n1 peces, se le ha suministrado el tratamiento 1 - A la muestra 2, formada por n2 peces, se le ha suministrado el tratamiento 2 Por lo tanto, el n\u00famero total de peces que hemos tratado ser\u00e1 n = n1 + n2 . Para saber si el tipo del tratamiento influye en el gen mutante , vamos a comparar las medias de ambas muestras, tenemos que ver cu\u00e1l de los siguientes casos ocurre: si hay o no hay diferencia significativa comparando los intervalos de confianza: Leyenda * \u03bc = media de la muestra * |-------- \u03bc --------| = Intervalo de Confianza * s = Cuasivarianza * \u03b1 = nivel de confianza Caso 1: No hay diferencia significativa |-------- \u03bc1 --------| |-------- \u03bc2 --------| Caso 2: S\u00ed hay diferencia significativa |-------- \u03bc1 --------| |-------- \u03bc2 --------| Plantearemos, lo primero, las hip\u00f3tesis, siendo H0 la hip\u00f3tesis nula: H0: \u03bc1 - \u03bc1 = 0 H1: \u03bc1 - \u03bc1 != 0 Despu\u00e9s, hay que considerar los casos de homocedasticidad y heterocedasticidad Homocedasticidad : Cuando la varianza del error condicional es constante: Nota : s es la varianza de una de las muestras Calcular t t = \u03bc1 - \u03bc1 / sqrt( s * (1/n1 + 1/n2)) Buscar el valor de t en la tabla para la confianza \u03b1 y con n1 + n2 \u2212 2 grados de libertad t_ = (1 \u2212 \u03b1) / 2, n1 + n2 \u2212 2 Comparar |t| > t_ heterocedasticidad : Cuando la varianza del error condicional no es constante: Nota : s1 es la varianza de la muestra 1 y s2 es la varianza de la muestra 2 Calcular t t = \u03bc1 - \u03bc1 / sqrt( s1/n1 + s2/n2) Buscar el valor de t en la tabla para la confianza \u03b1 y con n1 + n2 \u2212 2 grados de libertad t_ = (1 \u2212 \u03b1) / 2, n1 + n2 \u2212 2 Comparar |t| > t_","title":"M\u00e9todo 1: t de Student"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/tema_1/respuesta_continua/#metodo-2-analisis-de-la-varianza","text":"Este an\u00e1lisis permite averiguar si el resultado de un experimento es significativo, es decir: saber si hay que descartar la hip\u00f3tesis nula o aceptar la hip\u00f3tesis alternativa. Est\u00e1 indicado para variables y normales con igual varianza (homocedasticidad). Usamos ANOVA de un factor cuando queremos saber si las medias de una variable son diferentes entre los niveles o grupos de otra variable. Condiciones: En ANOVA de un factor solo se relacionan dos variables: una variable dependiente (o a explicar) y una variable independiente (que en esta t\u00e9cnica se suele llamar factor) La variable dependiente es cuantitativa (escalar) y la variable independiente es categ\u00f3rica (nominal u ordinal). Se pide que las variables sigan la distribuci\u00f3n normal, aunque como siempre esto es dif\u00edcil de cumplir en investigaciones sociales. Tambi\u00e9n que las varianzas (es decir, las desviaciones t\u00edpicas al cuadrado) de cada grupo de la variable independiente sean similiares (homocedasticidad). Aunque esto es lo ideal, en la realidad cuesta de cumplir, e igualmente se puede aplicar ANOVA El estad\u00edstico F o F-test (se llama F en honor al estad\u00edstico Ronald Fisher) se obtiene al estimar la variaci\u00f3n de las medias entre los grupos de la variable independiente y dividirla por la estimaci\u00f3n de la variaci\u00f3n de las medias dentro de los grupos. Si hacemos varios an\u00e1lisis de ANOVA de un factor, aquel con F m\u00e1s alto indicar\u00e1 que hay m\u00e1s diferencias y por tanto una relaci\u00f3n m\u00e1s fuerte entre las variables. Cuanto m\u00e1s difieren las medias de la variable dependiente entre los grupos de la variable independiente, m\u00e1s alto ser\u00e1 el valor de F. Met\u00e1fora de los Peces Mutantes Vamos a suponer que tenemos tres lagos de peces mutantes. Debido a la mutaci\u00f3n, los peces pueden tener n\u00fameros distintos de ojos (en concreto, de 1 a 10 ojos). En cada lago hay un tipo de mutaci\u00f3n distinta, y queremos saber c\u00f3mo influye el tipo de mutaci\u00f3n en el n\u00famero de ojos de los peces mutantes. Se establece una variable explicativa que, ser\u00e1 el n\u00famero de ojos por pez. En este caso, dir\u00edamos que la hip\u00f3tesis nula es que la media de ojos es la misma en los tres lagos y que, por lo tanto, no influye el tipo de mutaci\u00f3n en el n\u00famero de ojos de los peces mutantes. La hip\u00f3tesis alternativa es que la media de ojos es distinta y s\u00ed que influye. Valores necesarios: media de las tres muestras: m media de cada una de las muestras: m1 , m2 ... m_n n\u00famero total de valores: n n\u00famero de valores de cada muestra: n1 , n2 ... n_n n\u00famero de muestras: r Creamos la tabla ANOVA, donde SCE: Suma de Cuadrados de la variable Explicativa SCE = n1(m1 - m)^2 + n2(m2 - m)^2 + .. + n_n(m_n - m)^2 SCR: Suma de Cuadrados de la variable Residual SCR = (m1 - m)^2 + (m2 - m)^2 + .. + (m_n - m)^2 SCT: Suma de Cuadrados Total = SCE + SCR GLE: Grados de Libertad de la parte Explicativa = r \u2212 1 GLR: Grados de Libertad de la parte Residual = n \u2212 r GLT: Grados de Libertad Totales = GLE + GLR CME: Cuadrado Medio Explicado = SCE / GLE CMR: Cuadrado Medio Residual = SCR / GLR F = CME / CMR CMT: Cuadrado Medio Total Suma Cuadrados Cuadrados Medios Grados Libertad F p - valor Explicativa SCE CME GLE F p - valor Residual SCR CMR GLR Total SCT CMT GLT","title":"M\u00e9todo 2: An\u00e1lisis de la Varianza"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/tema_1/respuesta_dicotomica/","text":"Intenta dar una respuesta a una variable dicot\u00f3mica a trav\u00e9s de otra variable dicot\u00f3mica. Dicotom\u00eda: En la l\u00f3gica tradicional, la dicotom\u00eda es el desglose o fraccionamiento de un concepto gen\u00e9rico en uno de sus conceptos espec\u00edficos y su negaci\u00f3n. El concepto se refiere asimismo a la ley que establece que ninguna proposici\u00f3n puede ser verdadera y falsa al mismo tiempo. Por ejemplo: un caramelo puede ser con o sin az\u00facar, pero no puede ser con y sin az\u00facar al mismo tiempo. Introducci\u00f3n \u00b6 Met\u00e1fora de \"Los Peces Mutantes\" Un grupo de peces tiene una misma enfermedad. Hay dos tratamientos: A y B. A un grupo de n peces se les administra el tratamiento A, y al otro grupo el tratamiento B. Se observa qu\u00e9 peces se curan (CURADOS) y qu\u00e9 peces no se curan (NO CURADOS). Pez Tratamiento Curaci\u00f3n 1 A CURADO 2 A NO CURADO 3 B CURADO 4 A CURADO ... ... ... n - 1 B NO CURADO n B NO CURADO La pregunta es, \u00bfinfluye el tratamiento en la curaci\u00f3n ? Para ello, hay que comparar la proporci\u00f3n de los peces curados con el tratamiento A con la proporci\u00f3n de los peces curados con el tratamiento B. Vamos a ver dos m\u00e9todos que podemos emplear para contestar a esta pregunta. Para esto, se puede utilizar una muestra de peces del lago (no todos los peces del lago). Como demuestra el teorema central del l\u00edmite , nos podemos fiar de un conjunto lo suficientemente grande de datos para dar una respuesta a un problema que implica la totalidad del grupo de datos. Por ejemplo, supongamos que el problema de los peces ocurre en un lago en el que hay millones de peces que han sufrido una enfermedad debido a unos vertidos t\u00f3xicos. No necesitamos hacer el estudio con todos los millones de peces del lago para conocer qu\u00e9 tratamiento es necesario aplicar, sino que nos bastar\u00eda con una muestra de peces grande (que no te vale con diez pececillos para que se fiable, vaya) M\u00e9todo 1: z diferencia entre dos proporciones \u00b6 El objetivo de estas pruebas es evaluar las afirmaciones con respecto a una proporci\u00f3n de poblaci\u00f3n. Las pruebas se basan en la premisa de que una proporci\u00f3n muestral ser\u00e1 igual a la proporci\u00f3n verdadera de la poblaci\u00f3n si se toman m\u00e1rgenes o tolerancias para la variabilidad muestral ( teorema central del l\u00edmite ). Las pruebas suelen enfocarse en la diferencia entre un n\u00famero esperado de ocurrencias, suponiendo que una afirmaci\u00f3n es verdadera, y el n\u00famero observado realmente. El nivel de significancia es el valor que queremos establecer al formular la pregunta para poder afirmar la hip\u00f3tesis final. Es decir, un n\u00famero que al final lo utilizamos para hacer una comparativa con el resultado. La significancia la obtenemos de la distribuci\u00f3n normal z (de ah\u00ed que este m\u00e9todo se llame \"z diferencia\"). Dicho valor lo podemos obtener autom\u00e1ticamente si estamos programando, o manualmente en esta tabla, d\u00f3nde, por ejemplo: Una significancia de 0.025 tiene un valor z de -1.96 (fila 1.9, columna 0.06 ) z .00 .01 .02 .03 .04 .05 .06 .07 .08 .09 -4.0 0.00003 0.00003 0.00003 0.00003 0.00003 0.00003 0.00002 0.00002 0.00002 0.00002 -3.9 0.00005 0.00005 0.00004 0.00004 0.00004 0.00004 0.00004 0.00004 0.00003 0.00003 -3.8 0.00007 0.00007 0.00007 0.00006 0.00006 0.00006 0.00006 0.00005 0.00005 0.00005 -3.7 0.00011 0.00010 0.00010 0.00010 0.00009 0.00009 0.00008 0.00008 0.00008 0.00008 -3.6 0.00016 0.00015 0.00015 0.00014 0.00014 0.00013 0.00013 0.00012 0.00012 0.00011 -3.5 0.00023 0.00022 0.00022 0.00021 0.00020 0.00019 0.00019 0.00018 0.00017 0.00017 -3.4 0.00034 0.00032 0.00031 0.00030 0.00029 0.00028 0.00027 0.00026 0.00025 0.00024 -3.3 0.00048 0.00047 0.00045 0.00043 0.00042 0.00040 0.00039 0.00038 0.00036 0.00035 -3.2 0.00069 0.00066 0.00064 0.00062 0.00060 0.00058 0.00056 0.00054 0.00052 0.00050 -3.1 0.00097 0.00094 0.00090 0.00087 0.00084 0.00082 0.00079 0.00076 0.00074 0.00071 -3.0 0.00135 0.00131 0.00126 0.00122 0.00118 0.00114 0.00111 0.00107 0.00103 0.00100 -2.9 0.00187 0.00181 0.00175 0.00169 0.00164 0.00159 0.00154 0.00149 0.00144 0.00139 -2.8 0.00256 0.00248 0.00240 0.00233 0.00226 0.00219 0.00212 0.00205 0.00199 0.00193 -2.7 0.00347 0.00336 0.00326 0.00317 0.00307 0.00298 0.00289 0.00280 0.00272 0.00264 -2.6 0.00466 0.00453 0.00440 0.00427 0.00415 0.00402 0.00391 0.00379 0.00368 0.00357 -2.5 0.00621 0.00604 0.00587 0.00570 0.00554 0.00539 0.00523 0.00508 0.00494 0.00480 -2.4 0.00820 0.00798 0.00776 0.00755 0.00734 0.00714 0.00695 0.00676 0.00657 0.00639 -2.3 0.01072 0.01044 0.01017 0.00990 0.00964 0.00939 0.00914 0.00889 0.00866 0.00842 -2.2 0.01390 0.01355 0.01321 0.01287 0.01255 0.01222 0.01191 0.01160 0.01130 0.01101 -2.1 0.01786 0.01743 0.01700 0.01659 0.01618 0.01578 0.01539 0.01500 0.01463 0.01426 -2.0 0.02275 0.02222 0.02169 0.02118 0.02067 0.02018 0.01970 0.01923 0.01876 0.01831 -1.9 0.02872 0.02807 0.02743 0.02680 0.02619 0.02559 0.02500 0.02442 0.02385 0.02330 -1.8 0.03593 0.03515 0.03438 0.03362 0.03288 0.03216 0.03144 0.03074 0.03005 0.02938 -1.7 0.04456 0.04363 0.04272 0.04181 0.04093 0.04006 0.03920 0.03836 0.03754 0.03673 -1.6 0.05480 0.05370 0.05262 0.05155 0.05050 0.04947 0.04846 0.04746 0.04648 0.04551 -1.5 0.06681 0.06552 0.06425 0.06301 0.06178 0.06057 0.05938 0.05821 0.05705 0.05592 -1.4 0.08076 0.07927 0.07780 0.07636 0.07493 0.07353 0.07214 0.07078 0.06944 0.06811 -1.3 0.09680 0.09510 0.09342 0.09176 0.09012 0.08851 0.08691 0.08534 0.08379 0.08226 -1.2 0.11507 0.11314 0.11123 0.10935 0.10749 0.10565 0.10383 0.10204 0.10027 0.09852 -1.1 0.13566 0.13350 0.13136 0.12924 0.12714 0.12507 0.12302 0.12100 0.11900 0.11702 -1.0 0.15865 0.15625 0.15386 0.15150 0.14917 0.14686 0.14457 0.14231 0.14007 0.13786 -0.9 0.18406 0.18141 0.17878 0.17618 0.17361 0.17105 0.16853 0.16602 0.16354 0.16109 -0.8 0.21185 0.20897 0.20611 0.20327 0.20045 0.19766 0.19489 0.19215 0.18943 0.18673 -0.7 0.24196 0.23885 0.23576 0.23269 0.22965 0.22663 0.22363 0.22065 0.21769 0.21476 -0.6 0.27425 0.27093 0.26763 0.26434 0.26108 0.25784 0.25462 0.25143 0.24825 0.24509 -0.5 0.30853 0.30502 0.30153 0.29805 0.29460 0.29116 0.28774 0.28434 0.28095 0.27759 -0.4 0.34457 0.34090 0.33724 0.33359 0.32997 0.32635 0.32276 0.31917 0.31561 0.31206 -0.3 0.38209 0.37828 0.37448 0.37070 0.36692 0.36317 0.35942 0.35569 0.35197 0.34826 -0.2 0.42074 0.41683 0.41293 0.40904 0.40516 0.40129 0.39743 0.39358 0.38974 0.38590 -0.1 0.46017 0.45620 0.45224 0.44828 0.44433 0.44038 0.43644 0.43250 0.42857 0.42465 -0.0 0.50000 0.49601 0.49202 0.48803 0.48404 0.48006 0.47607 0.47209 0.46811 0.46414 Ejemplo Pr\u00e1ctico 1 \u00b6 Queremos saber si los caramelos de fresa suelen ser los preferidos, con respecto a los caramelos de lim\u00f3n, entre los Jugadores de Rugby Americanos y los Jugadores de Rugby Australianos , con un valor de significancia de 0.07. Se han tomado los siguientes datos: Dada una muestra de 200 jugadores americanos, se obtuvo que 56 de ellos prefieren los caramelos de fresa. Dada una muestra de 150 jugadores australianos, se obtuvo que, por el contrario, 29 de ellos prefieren los caramelos de lim\u00f3n. 1 - Hip\u00f3tesis: Hip\u00f3tesis 0: Ni fu ni fa Hip\u00f3tesis 1: Hay una diferencia de proporci\u00f3n Es muy importante enfatizar en que partimos de la premisa de que la hip\u00f3tesis 0 es verdadera, y que por esto utilizaremos la proporci\u00f3n combinada para descartar dicha hip\u00f3tesis (si la hip\u00f3tesis 0 es verdadera, no hay diferencia entre las proporciones) 2 - Diferencia de proporciones: Proporci\u00f3n de caramelos de fresa de la primera muestra: 56 / 200 = 0.28 Proporci\u00f3n de caramelos de lim\u00f3n de la segunda muestra: 29 / 150 = 0.193 Como 0.28 es mayor que 0.193 , queremos probar hip\u00f3tesis de que prefieren la fresa. diferencia_de_proporciones = 0,28 - 0,193 = 0,087 3 - Proporci\u00f3n combinada: Probabilidad de que la hip\u00f3tesis 0 sea correcta (o probabilidad de '\u00e9xito' de nuestra hip\u00f3tesis) probabilidad \u00e9xito (p) = 56 + 29 / 200 + 150 = 0,2429 probabilidad de fracaso (q) = 1 - p = 0,7571 Calcular la varianza de ambas muestras (a partir de las probabilidades de \u00e9xito y fracaso) p * q = 0,18389959 varianza muestra 1: p * q / 200 = 0,00091949795 varianza muestra 2: p * q / 150 = 0,001225997266667 4 - Calcular la desviaci\u00f3n estandar de la distribuci\u00f3n muestral de las diferencias de las proporciones muestrales: Por definici\u00f3n, la varianza te\u00f3rica de las dos muestras est\u00e1 dada por: La varianza de la muestra 1 m\u00e1s la varianza de la muestra 2 por la covariancia de ambas muestras por dos. Por lo tanto, la desviaci\u00f3n estandar (la z que queremos comparar con la significancia) ser\u00e1 la ra\u00edz cuadrada de la suma de la varianza de la muestra 1 con la varianza de la muestra 2: desviaci\u00f3n_est\u00e1ndar = ra\u00edz_cuadrada(varianza_muestra_1 + varianza_muestra_2) = 0,046319490677975 5 - Calcular el valor z: diferencia_de_proporciones / desviaci\u00f3n_est\u00e1ndar = 1,878258994790041 Comparar la z obtenida a trav\u00e9s de la significancia con la z obtenida a trav\u00e9s de la diferencia de proporciones z0 = 0.07 --> 1,48 z1 = 1,88 6 - Conclusi\u00f3n: Como 1,88 es mayor de 1,48 , rechazamos la primera hip\u00f3tesis (ni fu ni fa) y podemos concluir que, con un 7% de significancia, hay una diferencia de proporci\u00f3n entre pertenecer al equipo americano y preferir los caramelos de fresa. M\u00e9todo 2: Exacta de Fisher \u00b6 Este m\u00e9todo se utiliza para tama\u00f1os de muestra peque\u00f1os . Se utiliza, para ello, una tabla de contingencia que relaciona las variables de las dos muestras. 1 - C\u00e1lculo del p-valor El p-valor consiste en calcular la probabilidad exacta de observar un conjunto concreto de cuatro frecuencias: a, b, c y d. Con el ejemplo de los jugadores de rugby, ser\u00eda: Jugador de Rugby Americano Jugador de Rugby Australiano Prefiere los caramelos de fresa Prefiere los caramelos de lim\u00f3n Jugador / Caramelo Preferencia Fresa Preferencia Lim\u00f3n Total Americano a b a + b Australiano c d c + d Total a + c b + d n p_valor = (a+b)!(a+c)!(b+d)!(c+d)! / n!a!b!c!d! 2 - Comparar p_valor con el nivel de significancia alfa. p < alfa , se rechaza la hip\u00f3tesis p >= alfa , se acepta la hip\u00f3tesis Ejemplo Pr\u00e1ctico 2 \u00b6 Tenemos una muestra de 35 jugadores: 17 jugadores americanos y 18 australianos. Del grupo de los jugadores americanos, 10 de ellos prefieren los caramelos de fresa, y los 7 restantes los de lim\u00f3n. Por otro lado, 5 de los jugadores australianos prefieren los caramelos de fresa y 13 los de lim\u00f3n. La variable explicativa es la nacionalidad del equipo, y la variable respuesta la preferencia de sabor (fresa o lim\u00f3n) Tabla: Jugador / Caramelo Preferencia Fresa Preferencia Lim\u00f3n Total Americano 10 7 17 Australiano 5 13 18 Total 15 20 35 p_valor = 17!18!15!20! / 35!10!7!5!13! = 0,092 Conclusi\u00f3n: Como 0,092 es menor que el valor de significancia, no se rechaza la hip\u00f3tesis nula ya que no hay evidencia para concluir que la variable explicativa influya en la variable respuesta de forma significativa. Es decir, no es significante la nacionalidad del equipo para que prefiera los caramelos de fresa sobre los de lim\u00f3n.","title":"Respuesta Dicot\u00f3mica"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/tema_1/respuesta_dicotomica/#introduccion","text":"Met\u00e1fora de \"Los Peces Mutantes\" Un grupo de peces tiene una misma enfermedad. Hay dos tratamientos: A y B. A un grupo de n peces se les administra el tratamiento A, y al otro grupo el tratamiento B. Se observa qu\u00e9 peces se curan (CURADOS) y qu\u00e9 peces no se curan (NO CURADOS). Pez Tratamiento Curaci\u00f3n 1 A CURADO 2 A NO CURADO 3 B CURADO 4 A CURADO ... ... ... n - 1 B NO CURADO n B NO CURADO La pregunta es, \u00bfinfluye el tratamiento en la curaci\u00f3n ? Para ello, hay que comparar la proporci\u00f3n de los peces curados con el tratamiento A con la proporci\u00f3n de los peces curados con el tratamiento B. Vamos a ver dos m\u00e9todos que podemos emplear para contestar a esta pregunta. Para esto, se puede utilizar una muestra de peces del lago (no todos los peces del lago). Como demuestra el teorema central del l\u00edmite , nos podemos fiar de un conjunto lo suficientemente grande de datos para dar una respuesta a un problema que implica la totalidad del grupo de datos. Por ejemplo, supongamos que el problema de los peces ocurre en un lago en el que hay millones de peces que han sufrido una enfermedad debido a unos vertidos t\u00f3xicos. No necesitamos hacer el estudio con todos los millones de peces del lago para conocer qu\u00e9 tratamiento es necesario aplicar, sino que nos bastar\u00eda con una muestra de peces grande (que no te vale con diez pececillos para que se fiable, vaya)","title":"Introducci\u00f3n"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/tema_1/respuesta_dicotomica/#metodo-1-z-diferencia-entre-dos-proporciones","text":"El objetivo de estas pruebas es evaluar las afirmaciones con respecto a una proporci\u00f3n de poblaci\u00f3n. Las pruebas se basan en la premisa de que una proporci\u00f3n muestral ser\u00e1 igual a la proporci\u00f3n verdadera de la poblaci\u00f3n si se toman m\u00e1rgenes o tolerancias para la variabilidad muestral ( teorema central del l\u00edmite ). Las pruebas suelen enfocarse en la diferencia entre un n\u00famero esperado de ocurrencias, suponiendo que una afirmaci\u00f3n es verdadera, y el n\u00famero observado realmente. El nivel de significancia es el valor que queremos establecer al formular la pregunta para poder afirmar la hip\u00f3tesis final. Es decir, un n\u00famero que al final lo utilizamos para hacer una comparativa con el resultado. La significancia la obtenemos de la distribuci\u00f3n normal z (de ah\u00ed que este m\u00e9todo se llame \"z diferencia\"). Dicho valor lo podemos obtener autom\u00e1ticamente si estamos programando, o manualmente en esta tabla, d\u00f3nde, por ejemplo: Una significancia de 0.025 tiene un valor z de -1.96 (fila 1.9, columna 0.06 ) z .00 .01 .02 .03 .04 .05 .06 .07 .08 .09 -4.0 0.00003 0.00003 0.00003 0.00003 0.00003 0.00003 0.00002 0.00002 0.00002 0.00002 -3.9 0.00005 0.00005 0.00004 0.00004 0.00004 0.00004 0.00004 0.00004 0.00003 0.00003 -3.8 0.00007 0.00007 0.00007 0.00006 0.00006 0.00006 0.00006 0.00005 0.00005 0.00005 -3.7 0.00011 0.00010 0.00010 0.00010 0.00009 0.00009 0.00008 0.00008 0.00008 0.00008 -3.6 0.00016 0.00015 0.00015 0.00014 0.00014 0.00013 0.00013 0.00012 0.00012 0.00011 -3.5 0.00023 0.00022 0.00022 0.00021 0.00020 0.00019 0.00019 0.00018 0.00017 0.00017 -3.4 0.00034 0.00032 0.00031 0.00030 0.00029 0.00028 0.00027 0.00026 0.00025 0.00024 -3.3 0.00048 0.00047 0.00045 0.00043 0.00042 0.00040 0.00039 0.00038 0.00036 0.00035 -3.2 0.00069 0.00066 0.00064 0.00062 0.00060 0.00058 0.00056 0.00054 0.00052 0.00050 -3.1 0.00097 0.00094 0.00090 0.00087 0.00084 0.00082 0.00079 0.00076 0.00074 0.00071 -3.0 0.00135 0.00131 0.00126 0.00122 0.00118 0.00114 0.00111 0.00107 0.00103 0.00100 -2.9 0.00187 0.00181 0.00175 0.00169 0.00164 0.00159 0.00154 0.00149 0.00144 0.00139 -2.8 0.00256 0.00248 0.00240 0.00233 0.00226 0.00219 0.00212 0.00205 0.00199 0.00193 -2.7 0.00347 0.00336 0.00326 0.00317 0.00307 0.00298 0.00289 0.00280 0.00272 0.00264 -2.6 0.00466 0.00453 0.00440 0.00427 0.00415 0.00402 0.00391 0.00379 0.00368 0.00357 -2.5 0.00621 0.00604 0.00587 0.00570 0.00554 0.00539 0.00523 0.00508 0.00494 0.00480 -2.4 0.00820 0.00798 0.00776 0.00755 0.00734 0.00714 0.00695 0.00676 0.00657 0.00639 -2.3 0.01072 0.01044 0.01017 0.00990 0.00964 0.00939 0.00914 0.00889 0.00866 0.00842 -2.2 0.01390 0.01355 0.01321 0.01287 0.01255 0.01222 0.01191 0.01160 0.01130 0.01101 -2.1 0.01786 0.01743 0.01700 0.01659 0.01618 0.01578 0.01539 0.01500 0.01463 0.01426 -2.0 0.02275 0.02222 0.02169 0.02118 0.02067 0.02018 0.01970 0.01923 0.01876 0.01831 -1.9 0.02872 0.02807 0.02743 0.02680 0.02619 0.02559 0.02500 0.02442 0.02385 0.02330 -1.8 0.03593 0.03515 0.03438 0.03362 0.03288 0.03216 0.03144 0.03074 0.03005 0.02938 -1.7 0.04456 0.04363 0.04272 0.04181 0.04093 0.04006 0.03920 0.03836 0.03754 0.03673 -1.6 0.05480 0.05370 0.05262 0.05155 0.05050 0.04947 0.04846 0.04746 0.04648 0.04551 -1.5 0.06681 0.06552 0.06425 0.06301 0.06178 0.06057 0.05938 0.05821 0.05705 0.05592 -1.4 0.08076 0.07927 0.07780 0.07636 0.07493 0.07353 0.07214 0.07078 0.06944 0.06811 -1.3 0.09680 0.09510 0.09342 0.09176 0.09012 0.08851 0.08691 0.08534 0.08379 0.08226 -1.2 0.11507 0.11314 0.11123 0.10935 0.10749 0.10565 0.10383 0.10204 0.10027 0.09852 -1.1 0.13566 0.13350 0.13136 0.12924 0.12714 0.12507 0.12302 0.12100 0.11900 0.11702 -1.0 0.15865 0.15625 0.15386 0.15150 0.14917 0.14686 0.14457 0.14231 0.14007 0.13786 -0.9 0.18406 0.18141 0.17878 0.17618 0.17361 0.17105 0.16853 0.16602 0.16354 0.16109 -0.8 0.21185 0.20897 0.20611 0.20327 0.20045 0.19766 0.19489 0.19215 0.18943 0.18673 -0.7 0.24196 0.23885 0.23576 0.23269 0.22965 0.22663 0.22363 0.22065 0.21769 0.21476 -0.6 0.27425 0.27093 0.26763 0.26434 0.26108 0.25784 0.25462 0.25143 0.24825 0.24509 -0.5 0.30853 0.30502 0.30153 0.29805 0.29460 0.29116 0.28774 0.28434 0.28095 0.27759 -0.4 0.34457 0.34090 0.33724 0.33359 0.32997 0.32635 0.32276 0.31917 0.31561 0.31206 -0.3 0.38209 0.37828 0.37448 0.37070 0.36692 0.36317 0.35942 0.35569 0.35197 0.34826 -0.2 0.42074 0.41683 0.41293 0.40904 0.40516 0.40129 0.39743 0.39358 0.38974 0.38590 -0.1 0.46017 0.45620 0.45224 0.44828 0.44433 0.44038 0.43644 0.43250 0.42857 0.42465 -0.0 0.50000 0.49601 0.49202 0.48803 0.48404 0.48006 0.47607 0.47209 0.46811 0.46414","title":"M\u00e9todo 1: z diferencia entre dos proporciones"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/tema_1/respuesta_dicotomica/#ejemplo-practico-1","text":"Queremos saber si los caramelos de fresa suelen ser los preferidos, con respecto a los caramelos de lim\u00f3n, entre los Jugadores de Rugby Americanos y los Jugadores de Rugby Australianos , con un valor de significancia de 0.07. Se han tomado los siguientes datos: Dada una muestra de 200 jugadores americanos, se obtuvo que 56 de ellos prefieren los caramelos de fresa. Dada una muestra de 150 jugadores australianos, se obtuvo que, por el contrario, 29 de ellos prefieren los caramelos de lim\u00f3n. 1 - Hip\u00f3tesis: Hip\u00f3tesis 0: Ni fu ni fa Hip\u00f3tesis 1: Hay una diferencia de proporci\u00f3n Es muy importante enfatizar en que partimos de la premisa de que la hip\u00f3tesis 0 es verdadera, y que por esto utilizaremos la proporci\u00f3n combinada para descartar dicha hip\u00f3tesis (si la hip\u00f3tesis 0 es verdadera, no hay diferencia entre las proporciones) 2 - Diferencia de proporciones: Proporci\u00f3n de caramelos de fresa de la primera muestra: 56 / 200 = 0.28 Proporci\u00f3n de caramelos de lim\u00f3n de la segunda muestra: 29 / 150 = 0.193 Como 0.28 es mayor que 0.193 , queremos probar hip\u00f3tesis de que prefieren la fresa. diferencia_de_proporciones = 0,28 - 0,193 = 0,087 3 - Proporci\u00f3n combinada: Probabilidad de que la hip\u00f3tesis 0 sea correcta (o probabilidad de '\u00e9xito' de nuestra hip\u00f3tesis) probabilidad \u00e9xito (p) = 56 + 29 / 200 + 150 = 0,2429 probabilidad de fracaso (q) = 1 - p = 0,7571 Calcular la varianza de ambas muestras (a partir de las probabilidades de \u00e9xito y fracaso) p * q = 0,18389959 varianza muestra 1: p * q / 200 = 0,00091949795 varianza muestra 2: p * q / 150 = 0,001225997266667 4 - Calcular la desviaci\u00f3n estandar de la distribuci\u00f3n muestral de las diferencias de las proporciones muestrales: Por definici\u00f3n, la varianza te\u00f3rica de las dos muestras est\u00e1 dada por: La varianza de la muestra 1 m\u00e1s la varianza de la muestra 2 por la covariancia de ambas muestras por dos. Por lo tanto, la desviaci\u00f3n estandar (la z que queremos comparar con la significancia) ser\u00e1 la ra\u00edz cuadrada de la suma de la varianza de la muestra 1 con la varianza de la muestra 2: desviaci\u00f3n_est\u00e1ndar = ra\u00edz_cuadrada(varianza_muestra_1 + varianza_muestra_2) = 0,046319490677975 5 - Calcular el valor z: diferencia_de_proporciones / desviaci\u00f3n_est\u00e1ndar = 1,878258994790041 Comparar la z obtenida a trav\u00e9s de la significancia con la z obtenida a trav\u00e9s de la diferencia de proporciones z0 = 0.07 --> 1,48 z1 = 1,88 6 - Conclusi\u00f3n: Como 1,88 es mayor de 1,48 , rechazamos la primera hip\u00f3tesis (ni fu ni fa) y podemos concluir que, con un 7% de significancia, hay una diferencia de proporci\u00f3n entre pertenecer al equipo americano y preferir los caramelos de fresa.","title":"Ejemplo Pr\u00e1ctico 1"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/tema_1/respuesta_dicotomica/#metodo-2-exacta-de-fisher","text":"Este m\u00e9todo se utiliza para tama\u00f1os de muestra peque\u00f1os . Se utiliza, para ello, una tabla de contingencia que relaciona las variables de las dos muestras. 1 - C\u00e1lculo del p-valor El p-valor consiste en calcular la probabilidad exacta de observar un conjunto concreto de cuatro frecuencias: a, b, c y d. Con el ejemplo de los jugadores de rugby, ser\u00eda: Jugador de Rugby Americano Jugador de Rugby Australiano Prefiere los caramelos de fresa Prefiere los caramelos de lim\u00f3n Jugador / Caramelo Preferencia Fresa Preferencia Lim\u00f3n Total Americano a b a + b Australiano c d c + d Total a + c b + d n p_valor = (a+b)!(a+c)!(b+d)!(c+d)! / n!a!b!c!d! 2 - Comparar p_valor con el nivel de significancia alfa. p < alfa , se rechaza la hip\u00f3tesis p >= alfa , se acepta la hip\u00f3tesis","title":"M\u00e9todo 2: Exacta de Fisher"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/tema_1/respuesta_dicotomica/#ejemplo-practico-2","text":"Tenemos una muestra de 35 jugadores: 17 jugadores americanos y 18 australianos. Del grupo de los jugadores americanos, 10 de ellos prefieren los caramelos de fresa, y los 7 restantes los de lim\u00f3n. Por otro lado, 5 de los jugadores australianos prefieren los caramelos de fresa y 13 los de lim\u00f3n. La variable explicativa es la nacionalidad del equipo, y la variable respuesta la preferencia de sabor (fresa o lim\u00f3n) Tabla: Jugador / Caramelo Preferencia Fresa Preferencia Lim\u00f3n Total Americano 10 7 17 Australiano 5 13 18 Total 15 20 35 p_valor = 17!18!15!20! / 35!10!7!5!13! = 0,092 Conclusi\u00f3n: Como 0,092 es menor que el valor de significancia, no se rechaza la hip\u00f3tesis nula ya que no hay evidencia para concluir que la variable explicativa influya en la variable respuesta de forma significativa. Es decir, no es significante la nacionalidad del equipo para que prefiera los caramelos de fresa sobre los de lim\u00f3n.","title":"Ejemplo Pr\u00e1ctico 2"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/tema_1/respuesta_nominal/","text":"Respuesta Nominal \u00b6 Se est\u00e1 intentando explicar la variable respuesta Y nominal a trav\u00e9s de la variable explicativa X nominal. Se da, por ejemplo, cuando se quiere estudiar si distintos tipos de efectos adversos est\u00e1n influidos por distintos tipos de dieta. Para ello se realiza un estudio en n individuos a los que se les asigna, por ejemplo, la dieta 1 (codificada con 1 en la variable dieta) a n1 individuos, la dieta 2 (codificada con 2), la dieta 3 (codificada con 3) a n3 individuos, con n = n1 + n2 + n3 y se observa qu\u00e9 tipo de efecto adverso presenta (por ejemplo, 1, 2, 3 o 4). Nota: Una respuesta dicot\u00f3mica es una respuesta nominal de dos valores Contraste de Hip\u00f3tesis La pregunta de si X influye en Y se traduce en realizar el contraste de hip\u00f3tesis H0 : No diferencia en los grupos H1 : S\u00ed diferencia en los grupos \u03c72 de homogeneidad \u00b6 \u03c72 = chi cuadrado Valores X = 1 X = 2 X = 3 Y = 1 n11 n12 n13 r1 Y = 2 n21 n22 n23 r2 Y = 3 n31 n32 n33 r3 Y = 4 n41 n42 n43 r4 c1 c2 c3 n Calcular \u03c72: e_ij = r_i * c_j / n \u03c72 = (n_ij - e_ij) ^ 2 / e_ij Calcular p_valor (buscando en la tabla): (tabla pchisq = tabla chi cuadrado) p_valor = 1 \u2212 pchisq(\u03c72, grado_de_libertad)","title":"Respuesta Nominal"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/tema_1/respuesta_nominal/#respuesta-nominal","text":"Se est\u00e1 intentando explicar la variable respuesta Y nominal a trav\u00e9s de la variable explicativa X nominal. Se da, por ejemplo, cuando se quiere estudiar si distintos tipos de efectos adversos est\u00e1n influidos por distintos tipos de dieta. Para ello se realiza un estudio en n individuos a los que se les asigna, por ejemplo, la dieta 1 (codificada con 1 en la variable dieta) a n1 individuos, la dieta 2 (codificada con 2), la dieta 3 (codificada con 3) a n3 individuos, con n = n1 + n2 + n3 y se observa qu\u00e9 tipo de efecto adverso presenta (por ejemplo, 1, 2, 3 o 4). Nota: Una respuesta dicot\u00f3mica es una respuesta nominal de dos valores Contraste de Hip\u00f3tesis La pregunta de si X influye en Y se traduce en realizar el contraste de hip\u00f3tesis H0 : No diferencia en los grupos H1 : S\u00ed diferencia en los grupos","title":"Respuesta Nominal"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/tema_1/respuesta_nominal/#2-de-homogeneidad","text":"\u03c72 = chi cuadrado Valores X = 1 X = 2 X = 3 Y = 1 n11 n12 n13 r1 Y = 2 n21 n22 n23 r2 Y = 3 n31 n32 n33 r3 Y = 4 n41 n42 n43 r4 c1 c2 c3 n Calcular \u03c72: e_ij = r_i * c_j / n \u03c72 = (n_ij - e_ij) ^ 2 / e_ij Calcular p_valor (buscando en la tabla): (tabla pchisq = tabla chi cuadrado) p_valor = 1 \u2212 pchisq(\u03c72, grado_de_libertad)","title":"\u03c72 de homogeneidad"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/tema_1/respuesta_ordinal/","text":"Respuesta Ordinal \u00b6 Una respuesta ordinal es aquella que puede obtener valores dentro de un rango num\u00e9rico ordenado. En esta secci\u00f3n se ven tres m\u00e9todos: Nota: En los siguientes tests, tambi\u00e9n vale para una variable respuesta Y nominal si dicha variable respuesta Y no es normal en cada categor\u00eda. A trav\u00e9s de una variable X explicativa dicot\u00f3mica: U de Mann-Whitney W de Wilcoxon Nota: ambos tests son equivalentes A trav\u00e9s de una variable X explicativa nominal: H de Kruskal-Wallis Met\u00e1fora de los peces mutantes Supongamos que clasificamos a los peces seg\u00fan un grado de mutaci\u00f3n que puede variar del 1 al 5, siendo 1 poco mutante y 5 muy mutante. U de Mann-Whitney \u00b6 En este caso, tendremos 2 tratamientos y analizaremos 2 muestras de peces. Formulaci\u00f3n de la hip\u00f3tesis: H0 : F1 = F2 H1 : F1 != F2 Valores: N\u00famero de valores por muestra: n1 y n2 N\u00famero total de valores: n Mediana de cada muestra: m1 y m2 Rango intercuart\u00edlico de cada muestra: r1 y r2 N\u00famero de valores distintos que se produce para cada valor de la variable respuesta sin distinguir grupos: k N\u00famero de empates desde j = 1 hasta j = k: d_1 ... d_k sumatorio j=1, k ==> d^3 - d U = sqrt((1 / 12) * ((n1 * n2)/n(n - 1)) * (n^3 - n - sumatorio)) W de Wilcoxon \u00b6 H de Kruskal-Wallis \u00b6 Formulaci\u00f3n de la hip\u00f3tesis: H0 : F1 = F2 = F3 = ... = Fn H1 : Alguna Fi distinta","title":"Respuesta Ordinal"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/tema_1/respuesta_ordinal/#respuesta-ordinal","text":"Una respuesta ordinal es aquella que puede obtener valores dentro de un rango num\u00e9rico ordenado. En esta secci\u00f3n se ven tres m\u00e9todos: Nota: En los siguientes tests, tambi\u00e9n vale para una variable respuesta Y nominal si dicha variable respuesta Y no es normal en cada categor\u00eda. A trav\u00e9s de una variable X explicativa dicot\u00f3mica: U de Mann-Whitney W de Wilcoxon Nota: ambos tests son equivalentes A trav\u00e9s de una variable X explicativa nominal: H de Kruskal-Wallis Met\u00e1fora de los peces mutantes Supongamos que clasificamos a los peces seg\u00fan un grado de mutaci\u00f3n que puede variar del 1 al 5, siendo 1 poco mutante y 5 muy mutante.","title":"Respuesta Ordinal"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/tema_1/respuesta_ordinal/#u-de-mann-whitney","text":"En este caso, tendremos 2 tratamientos y analizaremos 2 muestras de peces. Formulaci\u00f3n de la hip\u00f3tesis: H0 : F1 = F2 H1 : F1 != F2 Valores: N\u00famero de valores por muestra: n1 y n2 N\u00famero total de valores: n Mediana de cada muestra: m1 y m2 Rango intercuart\u00edlico de cada muestra: r1 y r2 N\u00famero de valores distintos que se produce para cada valor de la variable respuesta sin distinguir grupos: k N\u00famero de empates desde j = 1 hasta j = k: d_1 ... d_k sumatorio j=1, k ==> d^3 - d U = sqrt((1 / 12) * ((n1 * n2)/n(n - 1)) * (n^3 - n - sumatorio))","title":"U de Mann-Whitney"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/tema_1/respuesta_ordinal/#w-de-wilcoxon","text":"","title":"W de Wilcoxon"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/tema_1/respuesta_ordinal/#h-de-kruskal-wallis","text":"Formulaci\u00f3n de la hip\u00f3tesis: H0 : F1 = F2 = F3 = ... = Fn H1 : Alguna Fi distinta","title":"H de Kruskal-Wallis"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/tema_2/","text":"En estad\u00edstica, las tablas de contingencia se emplean para registrar y analizar la asociaci\u00f3n entre dos o m\u00e1s variables, habitualmente de naturaleza cualitativa (nominales u ordinales) X = 1 X = 0 Total Y = 1 a b r1 Y = 0 c d r0 Total s1 s0 n Dise\u00f1os Prospectivos \u00b6 De la tabla, se fijan: s1 y s0 En los dise\u00f1os prospectivos se pueden utilizar como \u00edndices de riesgos la diferencia de riesgos, el riesgo relativo y el odds ratio. Dise\u00f1os Retrospectivos \u00b6 De la tabla, se fijan: r1 y r0 En los dise\u00f1os retrospectivos y en los transversales el odds ratio. Dise\u00f1os Transversales \u00b6 De la tabla, se fija: n","title":"Introducci\u00f3n"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/tema_2/#disenos-prospectivos","text":"De la tabla, se fijan: s1 y s0 En los dise\u00f1os prospectivos se pueden utilizar como \u00edndices de riesgos la diferencia de riesgos, el riesgo relativo y el odds ratio.","title":"Dise\u00f1os Prospectivos"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/tema_2/#disenos-retrospectivos","text":"De la tabla, se fijan: r1 y r0 En los dise\u00f1os retrospectivos y en los transversales el odds ratio.","title":"Dise\u00f1os Retrospectivos"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/tema_2/#disenos-transversales","text":"De la tabla, se fija: n","title":"Dise\u00f1os Transversales"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/tema_2/indices_absolutos/","text":"Diferencia de Riesgos v\u00e1lida en estudios prospectivos \u00b6 El riesgo es un par\u00e1metro poblacional. El riesgo absoluto mide la incidencia de un evento en la poblaci\u00f3n total : es la probabilidad que tiene un sujeto de sufrir un evento a lo largo de cierto tiempo . De lo anterior se desprende que la incidencia de un evento en una poblaci\u00f3n se denomina riesgo absoluto . Se pueden utilizar los siguientes m\u00e9todos: Test z de diferencia de proporciones Test de Fisher Test \u03c7^2 Para estimar el par\u00e1metro dr ( diferencia de riesgos ) se considera el estad\u00edstico \u0398 dado por la variable aleatoria (v.a.) \u03a011 \u2212 \u03a010 , siendo \u03a011 (Y = 1, X = 1) e \u03a010 (Y = 1, X = 0) las proporciones muestrales entendidas como v.a. ya que variar \u0301an de muestra a muestra Viene dado por: riesgo = \u03b8 = dr = \u03c011 \u2212 \u03c010 = P(Y = 1|X = 1) \u2212 P(Y = 1|X = 0) X = 1 X = 0 Total Y = 1 a b a + b Y = 0 c d c + d Total a + c b + d N Met\u00e1fora de los peces mutantes Peces Mutante Normal Total Expuestos a b a + b No expuestos c d c + d Total a + c b + d N Intervalo de confianza \u00b6 Nota: sigue una distribuci\u00f3n normal Varianza Te\u00f3rica: Varianza Te\u00f3rica = (\u03c011(1 - \u03c011) / (a + c)) + (\u03c010(1 - \u03c010) / (b + d)) Error Est\u00e1ndar: Error Est\u00e1ndar = sqrt(Varianza Te\u00f3rica) = sqrt( (\u03c011(1 - \u03c011) / (a + c)) + (\u03c010(1 - \u03c010) / (b + d)) ) Dado una significancia de \u03b1, calculamos el intervalo de confianza al (1 - \u03b1)% : IC dr = (a / a + c) - (b / b + d) \u2213 z_1-\u03b1/2 * sqrt((ac / (a+c)^3) + ((bd / (b+d)^3))) Contraste de hip\u00f3tesis \u00b6 H0 : dr = 0 H1 : dr != 0","title":"\u00cdndices Absolutos"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/tema_2/indices_absolutos/#diferencia-de-riesgos-valida-en-estudios-prospectivos","text":"El riesgo es un par\u00e1metro poblacional. El riesgo absoluto mide la incidencia de un evento en la poblaci\u00f3n total : es la probabilidad que tiene un sujeto de sufrir un evento a lo largo de cierto tiempo . De lo anterior se desprende que la incidencia de un evento en una poblaci\u00f3n se denomina riesgo absoluto . Se pueden utilizar los siguientes m\u00e9todos: Test z de diferencia de proporciones Test de Fisher Test \u03c7^2 Para estimar el par\u00e1metro dr ( diferencia de riesgos ) se considera el estad\u00edstico \u0398 dado por la variable aleatoria (v.a.) \u03a011 \u2212 \u03a010 , siendo \u03a011 (Y = 1, X = 1) e \u03a010 (Y = 1, X = 0) las proporciones muestrales entendidas como v.a. ya que variar \u0301an de muestra a muestra Viene dado por: riesgo = \u03b8 = dr = \u03c011 \u2212 \u03c010 = P(Y = 1|X = 1) \u2212 P(Y = 1|X = 0) X = 1 X = 0 Total Y = 1 a b a + b Y = 0 c d c + d Total a + c b + d N Met\u00e1fora de los peces mutantes Peces Mutante Normal Total Expuestos a b a + b No expuestos c d c + d Total a + c b + d N","title":"Diferencia de Riesgos v\u00e1lida en estudios prospectivos"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/tema_2/indices_absolutos/#intervalo-de-confianza","text":"Nota: sigue una distribuci\u00f3n normal Varianza Te\u00f3rica: Varianza Te\u00f3rica = (\u03c011(1 - \u03c011) / (a + c)) + (\u03c010(1 - \u03c010) / (b + d)) Error Est\u00e1ndar: Error Est\u00e1ndar = sqrt(Varianza Te\u00f3rica) = sqrt( (\u03c011(1 - \u03c011) / (a + c)) + (\u03c010(1 - \u03c010) / (b + d)) ) Dado una significancia de \u03b1, calculamos el intervalo de confianza al (1 - \u03b1)% : IC dr = (a / a + c) - (b / b + d) \u2213 z_1-\u03b1/2 * sqrt((ac / (a+c)^3) + ((bd / (b+d)^3)))","title":"Intervalo de confianza"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/tema_2/indices_absolutos/#contraste-de-hipotesis","text":"H0 : dr = 0 H1 : dr != 0","title":"Contraste de hip\u00f3tesis"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/tema_2/indices_relativos/","text":"Riesgo Relativo \u00b6 El Riesgo relativo es el cociente entre el riesgo en el grupo con el factor de exposici\u00f3n o factor de riesgo y el riesgo en el grupo de referencia, que no tiene el factor de exposici\u00f3n. Es un concepto estad\u00edstico utilizado como medida de asociaci\u00f3n entre la variable dependiente y la variable independiente. El riesgo relativo es v\u00e1lido en estudios prospectivos y el odds ratio en prospectivos, retrospectivos y transversales. A la hora de calcular intervalos de confianza para estos \u00edndices habr\u00e1 que utilizar el teorema de Taylor para variables aleatorias. X = 1 X = 0 Total Y = 1 a b a + b Y = 0 c d c + d Total a + c b + d N El rr es un \u00edndice relativo de asociaci\u00f3n entre dos variables dicot\u00f3micas y admite, por su definici\u00f3n, una interpretaci\u00f3n directa. Por ejemplo: Si rr = 3 > 1 , la probabilidad de presencia de Y en los individuos con X = 1 es el triple que la probabilidad de presencia de Y en los individuos con X = 0. Si rr = 1 , hay la misma probabilidad de presencia de Y en los individuos con X = 1 que en lo individuos con X = 0. Si rr = 1 / 3 , la probabilidad de presencia de Y en los individuos con X = 1 es un tercio de la probabilidad de presencia de Y en los individuos con X = 0. Al ser el riesgo relativo rr una v.a. asim\u00e9trica (su rango es (0, \u221e)), su distribuci\u00f3n es no normal . Es conveniente, por tanto, considerar una transformaci\u00f3n que consiga normalidad con media te\u00f3rica y varianza te\u00f3rica que se puedan estimar f\u00e1cilmente. Se puede demostrar que la transformaci\u00f3n logaritmo neperiano (Ln) consigue este prop\u00f3sito. A efectos te\u00f3ricos, ahora es \u03b8 = Ln(rr) . Para calcular el valor z_1-\u03b1/2 , se pueden utilizar los siguientes m\u00e9todos: Test z de diferencia de proporciones Test de Fisher Test \u03c7^2 Riesgo Relativo: riesgo_relativo = (a / (a+c)) / (b / (b+d)) Error Est\u00e1ndar: error_estandar = sqrt((1 / a) - (1 / (a+c)) + (1 / b) - (1 / (b+d))) Intervalo de Confianza: IC(1 \u2212 \u03b1)%(riesgo_relativo) = (exp(Ln(riesgo_relativo) +- z_1-\u03b1/2 * error_estandar)) Contraste de hip\u00f3tesis \u00b6 H0 : riesgo_relativo = 1 H1 : riesgo_relativo != 1 Odds Ratio \u00b6 En general, dada \u03c0 una proporci\u00f3n (probabilidad) cualquiera, se define el par\u00e1metro poblacional o , odds de una proporci\u00f3n, como el cociente de las probabilidades complementarias. Es decir, o = \u03c0 / 1\u2212\u03c0 , con lo que o \u2208 (0, \u221e) . En el caso de considerar el odds de enfermedad, su valor se interpreta de la forma siguiente: Si o = 3 > 1 , se tiene que la probabilidad de estar enfermo es el triple de la de estar sano, o lo que es lo mismo que P(Y = 1) = 3 / 3+1 = 0.75 y P(Y = 0) = 0.25. Si o = 1 , hay la misma probabilidad de estar enfermo que de estar sano. Si o = 1 / 3 , se tiene que la probabilidad de estar enfermo es un tercio de la de estar sano, o lo que es lo mismo que P(Y = 1) = (1/3) / (1/3+1) = 0.25 y P(Y = 0) = 0.75. . Utilizando el teorema de Bayes, es f\u00e1cil ver que orX = orY , es decir que el odds ratio de presencia de Y respecto a X es el mismo que el odds ratio de presencia de X respecto a Y . Por ello, se puede hablar simplemente de odds ratio, or , y se puede calcular en todo tipo de estudios. Por consiguiente: or = (ad / bc) Nota: por esto al odds ratio tambi\u00e9n se le llama raz\u00f3n de productos cruzados. El or es un \u00edndice relativo de asociaci\u00f3n entre dos variables dicot\u00f3micas y se puede demostrar los siguientes tres casos: or > 1 \u21d4 P(Y = 1|X = 1) > P(Y = 1|X = 0) , por lo que la presencia de X favorece la presencia de Y. or = 1 \u21d4 P(Y = 1|X = 1) = P(Y = 1|X = 0) , por lo que la presencia de X ni favorece ni desfavorece la presencia de Y. or < 1 \u21d4 P(Y = 1|X = 1) < P(Y = 1|X = 0) , por lo que la presencia de X desfavorece la presencia de Y. Lo que se traduce a: En el caso de que Y sea la variable \u201cEnfermedad\u201d codificada con 1 en el caso de \u201cS\u00ed enfermo\u201d y con 0 en el caso de \u201cNo enfermo\u201d y que X sea la variable \u201cExposici\u00f3n\u201d codificada con 1 en el caso de \u201cS\u00ed expuesto\u201d y con 0 en el caso de \u201cNo expuesto\u201d, la interpretaci\u00f3n anterior del or se puede hacer de forma m\u00e1s clara: Si or > 1 \u21d4 X es un factor de riesgo. Si or = 1 \u21d4 X no es ni un factor de riesgo ni un factor protector Si or < 1 \u21d4 X es un factor protector. Al ser el riesgo relativo or una v.a. asim\u00e9trica (su rango es (0, \u221e)), su distribuci\u00f3n es no normal . Es conveniente, por tanto, considerar una transformaci\u00f3n que consiga normalidad con media te\u00f3rica y varianza te\u00f3rica que se puedan estimar f\u00e1cilmente. Se puede demostrar que la transformaci\u00f3n logaritmo neperiano (Ln) consigue este prop\u00f3sito. A efectos te\u00f3ricos, ahora es \u03b8 = Ln(or) . Intervalo de confianza \u00b6 Nota: no sigue una distribuci\u00f3n normal Odds Ratio: odds_ration = ad / bc Error Est\u00e1ndar: error_estandar = sqrt(1/a + 1/b + 1/c + 1/d) Dado una significancia de \u03b1, calculamos el intervalo de confianza al (1 - \u03b1)% : Intervalo de Confianza: IC(1 \u2212 \u03b1)%(ad / bc) = exp(Ln(odds_ratio) +- z_1-\u03b1/2 * error_est\u00e1ndar)) Contraste de hip\u00f3tesis \u00b6 H0 : odds_ratio = 1 H1 : odds_ratio != 1","title":"\u00cdndices Relativos"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/tema_2/indices_relativos/#riesgo-relativo","text":"El Riesgo relativo es el cociente entre el riesgo en el grupo con el factor de exposici\u00f3n o factor de riesgo y el riesgo en el grupo de referencia, que no tiene el factor de exposici\u00f3n. Es un concepto estad\u00edstico utilizado como medida de asociaci\u00f3n entre la variable dependiente y la variable independiente. El riesgo relativo es v\u00e1lido en estudios prospectivos y el odds ratio en prospectivos, retrospectivos y transversales. A la hora de calcular intervalos de confianza para estos \u00edndices habr\u00e1 que utilizar el teorema de Taylor para variables aleatorias. X = 1 X = 0 Total Y = 1 a b a + b Y = 0 c d c + d Total a + c b + d N El rr es un \u00edndice relativo de asociaci\u00f3n entre dos variables dicot\u00f3micas y admite, por su definici\u00f3n, una interpretaci\u00f3n directa. Por ejemplo: Si rr = 3 > 1 , la probabilidad de presencia de Y en los individuos con X = 1 es el triple que la probabilidad de presencia de Y en los individuos con X = 0. Si rr = 1 , hay la misma probabilidad de presencia de Y en los individuos con X = 1 que en lo individuos con X = 0. Si rr = 1 / 3 , la probabilidad de presencia de Y en los individuos con X = 1 es un tercio de la probabilidad de presencia de Y en los individuos con X = 0. Al ser el riesgo relativo rr una v.a. asim\u00e9trica (su rango es (0, \u221e)), su distribuci\u00f3n es no normal . Es conveniente, por tanto, considerar una transformaci\u00f3n que consiga normalidad con media te\u00f3rica y varianza te\u00f3rica que se puedan estimar f\u00e1cilmente. Se puede demostrar que la transformaci\u00f3n logaritmo neperiano (Ln) consigue este prop\u00f3sito. A efectos te\u00f3ricos, ahora es \u03b8 = Ln(rr) . Para calcular el valor z_1-\u03b1/2 , se pueden utilizar los siguientes m\u00e9todos: Test z de diferencia de proporciones Test de Fisher Test \u03c7^2 Riesgo Relativo: riesgo_relativo = (a / (a+c)) / (b / (b+d)) Error Est\u00e1ndar: error_estandar = sqrt((1 / a) - (1 / (a+c)) + (1 / b) - (1 / (b+d))) Intervalo de Confianza: IC(1 \u2212 \u03b1)%(riesgo_relativo) = (exp(Ln(riesgo_relativo) +- z_1-\u03b1/2 * error_estandar))","title":"Riesgo Relativo"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/tema_2/indices_relativos/#contraste-de-hipotesis","text":"H0 : riesgo_relativo = 1 H1 : riesgo_relativo != 1","title":"Contraste de hip\u00f3tesis"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/tema_2/indices_relativos/#odds-ratio","text":"En general, dada \u03c0 una proporci\u00f3n (probabilidad) cualquiera, se define el par\u00e1metro poblacional o , odds de una proporci\u00f3n, como el cociente de las probabilidades complementarias. Es decir, o = \u03c0 / 1\u2212\u03c0 , con lo que o \u2208 (0, \u221e) . En el caso de considerar el odds de enfermedad, su valor se interpreta de la forma siguiente: Si o = 3 > 1 , se tiene que la probabilidad de estar enfermo es el triple de la de estar sano, o lo que es lo mismo que P(Y = 1) = 3 / 3+1 = 0.75 y P(Y = 0) = 0.25. Si o = 1 , hay la misma probabilidad de estar enfermo que de estar sano. Si o = 1 / 3 , se tiene que la probabilidad de estar enfermo es un tercio de la de estar sano, o lo que es lo mismo que P(Y = 1) = (1/3) / (1/3+1) = 0.25 y P(Y = 0) = 0.75. . Utilizando el teorema de Bayes, es f\u00e1cil ver que orX = orY , es decir que el odds ratio de presencia de Y respecto a X es el mismo que el odds ratio de presencia de X respecto a Y . Por ello, se puede hablar simplemente de odds ratio, or , y se puede calcular en todo tipo de estudios. Por consiguiente: or = (ad / bc) Nota: por esto al odds ratio tambi\u00e9n se le llama raz\u00f3n de productos cruzados. El or es un \u00edndice relativo de asociaci\u00f3n entre dos variables dicot\u00f3micas y se puede demostrar los siguientes tres casos: or > 1 \u21d4 P(Y = 1|X = 1) > P(Y = 1|X = 0) , por lo que la presencia de X favorece la presencia de Y. or = 1 \u21d4 P(Y = 1|X = 1) = P(Y = 1|X = 0) , por lo que la presencia de X ni favorece ni desfavorece la presencia de Y. or < 1 \u21d4 P(Y = 1|X = 1) < P(Y = 1|X = 0) , por lo que la presencia de X desfavorece la presencia de Y. Lo que se traduce a: En el caso de que Y sea la variable \u201cEnfermedad\u201d codificada con 1 en el caso de \u201cS\u00ed enfermo\u201d y con 0 en el caso de \u201cNo enfermo\u201d y que X sea la variable \u201cExposici\u00f3n\u201d codificada con 1 en el caso de \u201cS\u00ed expuesto\u201d y con 0 en el caso de \u201cNo expuesto\u201d, la interpretaci\u00f3n anterior del or se puede hacer de forma m\u00e1s clara: Si or > 1 \u21d4 X es un factor de riesgo. Si or = 1 \u21d4 X no es ni un factor de riesgo ni un factor protector Si or < 1 \u21d4 X es un factor protector. Al ser el riesgo relativo or una v.a. asim\u00e9trica (su rango es (0, \u221e)), su distribuci\u00f3n es no normal . Es conveniente, por tanto, considerar una transformaci\u00f3n que consiga normalidad con media te\u00f3rica y varianza te\u00f3rica que se puedan estimar f\u00e1cilmente. Se puede demostrar que la transformaci\u00f3n logaritmo neperiano (Ln) consigue este prop\u00f3sito. A efectos te\u00f3ricos, ahora es \u03b8 = Ln(or) .","title":"Odds Ratio"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/tema_2/indices_relativos/#intervalo-de-confianza","text":"Nota: no sigue una distribuci\u00f3n normal Odds Ratio: odds_ration = ad / bc Error Est\u00e1ndar: error_estandar = sqrt(1/a + 1/b + 1/c + 1/d) Dado una significancia de \u03b1, calculamos el intervalo de confianza al (1 - \u03b1)% : Intervalo de Confianza: IC(1 \u2212 \u03b1)%(ad / bc) = exp(Ln(odds_ratio) +- z_1-\u03b1/2 * error_est\u00e1ndar))","title":"Intervalo de confianza"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/tema_2/indices_relativos/#contraste-de-hipotesis_1","text":"H0 : odds_ratio = 1 H1 : odds_ratio != 1","title":"Contraste de hip\u00f3tesis"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/tema_3/diagnostico_continuo/","text":"Introducci\u00f3n \u00b6 X es una variable diagn\u00f3stico (explicativa) continua e Y una variable enfermedad (respuesta) dicot\u00f3mica. Un ejemplo de esta situaci\u00f3n ser\u00eda estudiar si el biomarcador dado por el PSA (X) sirve para diagnosticar el c\u00e1ncer de pr\u00f3stata (Y). Una forma de estudiar esta situaci\u00f3n es dicotomizar la variable X, a trav\u00e9s de una nueva X' para estar en un supuesto de diagn\u00f3stico dicot\u00f3mico definido como: Siendo c un punto de corte o umbral determinado de forma \u00f3ptima: X' = 0 para X >= c X' = 1 para X < c Donde: X' = 1 indica que la prueba diagn\u00f3stica afirma que el individuo est\u00e1 enfermo X' = 0 indica que la prueba diagn\u00f3stica afirma que el individuo est\u00e1 sano Y = 1 indica que la prueba diagn\u00f3stica afirma que el individuo est\u00e1 realmente enfermo Y = 0 indica que la prueba diagn\u00f3stica afirma que el individuo est\u00e1 realmente sano Por lo que, para calcular la sensibilidad , especificidad , fracci\u00f3n de verdaderos positivos y fracci\u00f3n de falsos positivos con respecto a c : sensibilidad(c) = P(X' = 1|Y = 1) = P(X \u2265 c|Y = 1) fracci\u00f3n de verdaderos positivos(c) = fvp(c) = sensibilidad(c) especificidad(c) = P(X' = 0|Y = 0) = P(X < c|Y = 0) fracci\u00f3n de falsos positivos(c) = ffp(c) = especificidad(c) Curvas roc \u00b6 A partir de las fracciones de verdaderos y falsos positivos se obtiene una curva. Se va obteniendo una curva a partir de distintos puntos de corte . Se define como: roc = \u201creceiver operating characteristic\u201d roc(\u00b7) = {(ffp(c), fvp(c)), c \u2208 (\u2212\u221e, +\u221e)} Se representa ffp(c) en el eje de abcisas y fvp(c) en el eje de ordeandas. \u00c1rea bajo la curva (auc) \u00b6 El \u00e1rea bajo la curva ( auc , area under de curve ) es la integral de 0 a 1 de roc(t)dt y constituye un \u00edndice de resumen de la bondad del biomarcador X. El auc se puede estimar por el m\u00e9todo trapezoidal de suma de \u00e1reas de trapecios (ya que, en la gr\u00e1fica, se forman trapecios): Ejemplo de una gr\u00e1fica de una curva roc: Se demuestra que son equivalentes el auc y el test U de Mann-Whitney M\u00e1s info en: General AUC calculated based on the trapezoidal rule","title":"Diagn\u00f3stico Continuo"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/tema_3/diagnostico_continuo/#introduccion","text":"X es una variable diagn\u00f3stico (explicativa) continua e Y una variable enfermedad (respuesta) dicot\u00f3mica. Un ejemplo de esta situaci\u00f3n ser\u00eda estudiar si el biomarcador dado por el PSA (X) sirve para diagnosticar el c\u00e1ncer de pr\u00f3stata (Y). Una forma de estudiar esta situaci\u00f3n es dicotomizar la variable X, a trav\u00e9s de una nueva X' para estar en un supuesto de diagn\u00f3stico dicot\u00f3mico definido como: Siendo c un punto de corte o umbral determinado de forma \u00f3ptima: X' = 0 para X >= c X' = 1 para X < c Donde: X' = 1 indica que la prueba diagn\u00f3stica afirma que el individuo est\u00e1 enfermo X' = 0 indica que la prueba diagn\u00f3stica afirma que el individuo est\u00e1 sano Y = 1 indica que la prueba diagn\u00f3stica afirma que el individuo est\u00e1 realmente enfermo Y = 0 indica que la prueba diagn\u00f3stica afirma que el individuo est\u00e1 realmente sano Por lo que, para calcular la sensibilidad , especificidad , fracci\u00f3n de verdaderos positivos y fracci\u00f3n de falsos positivos con respecto a c : sensibilidad(c) = P(X' = 1|Y = 1) = P(X \u2265 c|Y = 1) fracci\u00f3n de verdaderos positivos(c) = fvp(c) = sensibilidad(c) especificidad(c) = P(X' = 0|Y = 0) = P(X < c|Y = 0) fracci\u00f3n de falsos positivos(c) = ffp(c) = especificidad(c)","title":"Introducci\u00f3n"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/tema_3/diagnostico_continuo/#curvas-roc","text":"A partir de las fracciones de verdaderos y falsos positivos se obtiene una curva. Se va obteniendo una curva a partir de distintos puntos de corte . Se define como: roc = \u201creceiver operating characteristic\u201d roc(\u00b7) = {(ffp(c), fvp(c)), c \u2208 (\u2212\u221e, +\u221e)} Se representa ffp(c) en el eje de abcisas y fvp(c) en el eje de ordeandas.","title":"Curvas roc"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/tema_3/diagnostico_continuo/#area-bajo-la-curva-auc","text":"El \u00e1rea bajo la curva ( auc , area under de curve ) es la integral de 0 a 1 de roc(t)dt y constituye un \u00edndice de resumen de la bondad del biomarcador X. El auc se puede estimar por el m\u00e9todo trapezoidal de suma de \u00e1reas de trapecios (ya que, en la gr\u00e1fica, se forman trapecios): Ejemplo de una gr\u00e1fica de una curva roc: Se demuestra que son equivalentes el auc y el test U de Mann-Whitney M\u00e1s info en: General AUC calculated based on the trapezoidal rule","title":"\u00c1rea bajo la curva (auc)"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/tema_3/diagnostico_dicotomico/","text":"Introducci\u00f3n \u00b6 X = 1 indica que la prueba diagn\u00f3stica afirma que el individuo est\u00e1 enfermo X = 0 indica que la prueba diagn\u00f3stica afirma que el individuo est\u00e1 sano Y = 1 indica que la prueba diagn\u00f3stica afirma que el individuo est\u00e1 realmente enfermo Y = 0 indica que la prueba diagn\u00f3stica afirma que el individuo est\u00e1 realmente sano X = 1 X = 0 Total Y = 1 a = Verdadero Positivo b = Falso Negativo a + b Y = 0 c = Falso Positivo d = Verdadero Negativo c + d Total a + c b + d N En el caso de \u00edndices de riesgo, se indicar\u00eda si el individuo est\u00e1 expuesto o no a un \u00edndice de riesgo. Sensibilidad y especificidad \u00b6 La sensibilidad y especificidad son proporciones poblacionales (por lo tanto, comprendidas entre 0 y 1) Sensibilidad: \"Acierto en enfermos\u201d . Est\u00e1 dado por P(X = 1|Y = 1) sensibilidad = a / a + c Especificidad: \"Acierto en sanos\" . Est\u00e1 dado por P(X = 0|Y = 0) especificidad = d / b + d Fracci\u00f3n de verdaderos positivos = sensibilidad = P(X = 1|Y = 1) Fracci\u00f3n de falsos positivos = 1 - especificidad = 1 - P(X = 0|Y = 0) = P(X = 1|Y = 0) Se puede comprobar que se y es no dependen de la prevalencia (la probabilidad de enfermedad, \u03c0 = P(Y = 1) ), por lo que son \u00fatiles para reflejar la bondad de una prueba diagn\u00f3stica \u00cdndice de Youden: youden = se + es \u2212 1 Eficacia eficacia = \u03c0se + (1 \u2212 \u03c0)es Valor predictivo \u00b6 La principal diferencia de los valores predictivos con respecto a la sensibilidad y especificidad, es que los valores predictivos s\u00ed dependen de la prevalencia (la probabilidad de enfermedad, \u03c0 = P(Y = 1) ), por lo que no son \u00fatiles para reflejar la bondad de una prueba diagn\u00f3stica Positivo \u00b6 Par\u00e1metro poblacional que indica el acierto en los individuos positivos seg\u00fan la prueba diagn\u00f3stica valor_predictivo_positivo = \u03c011 = P(Y = 1|X = 1) = a / a + c Negativo \u00b6 Par\u00e1metro poblacional que indica el acierto en los individuos negativos seg\u00fan la prueba diagn\u00f3stica valor_predictivo_negativo = \u03c000 = P(Y = 0|X = 0) = d / b + d Raz\u00f3n de verosimilitud \u00b6 Las razones de verosimilitud no son proporciones sino razones (un cociente de proporciones, en este caso) y que est\u00e1n comprendidos en el intervalo (0, \u221e) . Por su definici\u00f3n, al ser en t\u00e9rminos de sensibilidad y especificidad, no dependen de la prevalencia. Al estar comprendidas en el intervalo (0, \u221e) , su distribuci\u00f3n no es normal . Por esto, utilizamos la transformaci\u00f3n logaritmo neperiano (Ln) para conseguir normalidad con media y varianza te\u00f3ricas que se puedan estimar f\u00e1cilmente. Positiva \u00b6 Par\u00e1metro poblacional que representa la ganancia de informaci\u00f3n cuando la prueba diagn\u00f3stica da positivo. Si razon_verosimilitud_positiva > 1 , es m\u00e1s probable que un resultado positivo en la prueba diagn\u00f3stica se d\u00e9 en un sujeto enfermo que en uno sano. razon_verosimilitud_positiva = \u03c011 / \u03c010 = P(Y = 1|X = 1) / P(Y = 1|X = 0) = sensibilidad / 1 - especificidad Error Estimado: error = Ln(sensibilidad / 1 - especificidad) error_estimado = sqrt( ((1 / (a+b)) * (1 - sensibilidad / sensibilidad)) + ((1 / (c+d)) * (especificidad / 1 - especificidad)) ) Intervalo de confianza: IC = exp(Ln(sensibilidad / 1 - especificidad)) +- z_1\u2212\u03b1/2 * error_estimado Negativa \u00b6 Par\u00e1metro poblacional que representa la ganancia de informaci\u00f3n cuando la prueba diagn\u00f3stica da negativo. Si razon_verosimilitud_negativa < 1 , es m\u00e1s probable que un resultado negativo en la prueba diagn\u00f3stica se d\u00e9 en un sujeto enfermo que en uno sano. razon_verosimilitud_negativa = \u03c011 / \u03c010 = P(Y = 0|X = 1) / P(Y = 0|X = 0) = 1 - sensibilidad / especificidad error = Ln(1 - sensibilidad / especificidad) error_estimado = sqrt( ((1 / (a+b)) * (especificidad / 1 - especificidad)) + ((1 / (c+d)) * (1 - sensibilidad / sensibilidad)) )","title":"Diagn\u00f3stico Dicot\u00f3mico"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/tema_3/diagnostico_dicotomico/#introduccion","text":"X = 1 indica que la prueba diagn\u00f3stica afirma que el individuo est\u00e1 enfermo X = 0 indica que la prueba diagn\u00f3stica afirma que el individuo est\u00e1 sano Y = 1 indica que la prueba diagn\u00f3stica afirma que el individuo est\u00e1 realmente enfermo Y = 0 indica que la prueba diagn\u00f3stica afirma que el individuo est\u00e1 realmente sano X = 1 X = 0 Total Y = 1 a = Verdadero Positivo b = Falso Negativo a + b Y = 0 c = Falso Positivo d = Verdadero Negativo c + d Total a + c b + d N En el caso de \u00edndices de riesgo, se indicar\u00eda si el individuo est\u00e1 expuesto o no a un \u00edndice de riesgo.","title":"Introducci\u00f3n"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/tema_3/diagnostico_dicotomico/#sensibilidad-y-especificidad","text":"La sensibilidad y especificidad son proporciones poblacionales (por lo tanto, comprendidas entre 0 y 1) Sensibilidad: \"Acierto en enfermos\u201d . Est\u00e1 dado por P(X = 1|Y = 1) sensibilidad = a / a + c Especificidad: \"Acierto en sanos\" . Est\u00e1 dado por P(X = 0|Y = 0) especificidad = d / b + d Fracci\u00f3n de verdaderos positivos = sensibilidad = P(X = 1|Y = 1) Fracci\u00f3n de falsos positivos = 1 - especificidad = 1 - P(X = 0|Y = 0) = P(X = 1|Y = 0) Se puede comprobar que se y es no dependen de la prevalencia (la probabilidad de enfermedad, \u03c0 = P(Y = 1) ), por lo que son \u00fatiles para reflejar la bondad de una prueba diagn\u00f3stica \u00cdndice de Youden: youden = se + es \u2212 1 Eficacia eficacia = \u03c0se + (1 \u2212 \u03c0)es","title":"Sensibilidad y especificidad"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/tema_3/diagnostico_dicotomico/#valor-predictivo","text":"La principal diferencia de los valores predictivos con respecto a la sensibilidad y especificidad, es que los valores predictivos s\u00ed dependen de la prevalencia (la probabilidad de enfermedad, \u03c0 = P(Y = 1) ), por lo que no son \u00fatiles para reflejar la bondad de una prueba diagn\u00f3stica","title":"Valor predictivo"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/tema_3/diagnostico_dicotomico/#positivo","text":"Par\u00e1metro poblacional que indica el acierto en los individuos positivos seg\u00fan la prueba diagn\u00f3stica valor_predictivo_positivo = \u03c011 = P(Y = 1|X = 1) = a / a + c","title":"Positivo"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/tema_3/diagnostico_dicotomico/#negativo","text":"Par\u00e1metro poblacional que indica el acierto en los individuos negativos seg\u00fan la prueba diagn\u00f3stica valor_predictivo_negativo = \u03c000 = P(Y = 0|X = 0) = d / b + d","title":"Negativo"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/tema_3/diagnostico_dicotomico/#razon-de-verosimilitud","text":"Las razones de verosimilitud no son proporciones sino razones (un cociente de proporciones, en este caso) y que est\u00e1n comprendidos en el intervalo (0, \u221e) . Por su definici\u00f3n, al ser en t\u00e9rminos de sensibilidad y especificidad, no dependen de la prevalencia. Al estar comprendidas en el intervalo (0, \u221e) , su distribuci\u00f3n no es normal . Por esto, utilizamos la transformaci\u00f3n logaritmo neperiano (Ln) para conseguir normalidad con media y varianza te\u00f3ricas que se puedan estimar f\u00e1cilmente.","title":"Raz\u00f3n de verosimilitud"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/tema_3/diagnostico_dicotomico/#positiva","text":"Par\u00e1metro poblacional que representa la ganancia de informaci\u00f3n cuando la prueba diagn\u00f3stica da positivo. Si razon_verosimilitud_positiva > 1 , es m\u00e1s probable que un resultado positivo en la prueba diagn\u00f3stica se d\u00e9 en un sujeto enfermo que en uno sano. razon_verosimilitud_positiva = \u03c011 / \u03c010 = P(Y = 1|X = 1) / P(Y = 1|X = 0) = sensibilidad / 1 - especificidad Error Estimado: error = Ln(sensibilidad / 1 - especificidad) error_estimado = sqrt( ((1 / (a+b)) * (1 - sensibilidad / sensibilidad)) + ((1 / (c+d)) * (especificidad / 1 - especificidad)) ) Intervalo de confianza: IC = exp(Ln(sensibilidad / 1 - especificidad)) +- z_1\u2212\u03b1/2 * error_estimado","title":"Positiva"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/tema_3/diagnostico_dicotomico/#negativa","text":"Par\u00e1metro poblacional que representa la ganancia de informaci\u00f3n cuando la prueba diagn\u00f3stica da negativo. Si razon_verosimilitud_negativa < 1 , es m\u00e1s probable que un resultado negativo en la prueba diagn\u00f3stica se d\u00e9 en un sujeto enfermo que en uno sano. razon_verosimilitud_negativa = \u03c011 / \u03c010 = P(Y = 0|X = 1) / P(Y = 0|X = 0) = 1 - sensibilidad / especificidad error = Ln(1 - sensibilidad / especificidad) error_estimado = sqrt( ((1 / (a+b)) * (especificidad / 1 - especificidad)) + ((1 / (c+d)) * (1 - sensibilidad / sensibilidad)) )","title":"Negativa"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/tema_4/ajuste_de_clasificacion/","text":"Tasa de error \u00b6 La precisi\u00f3n de un modelo depende tanto del ajuste de la regresi\u00f3n, como el caso del trade-off de sesgo y varianza, pero tambi\u00e9n depende la clasificaci\u00f3n. Supongamos que queremos estimar f bas\u00e1ndonos en los datos de entrenamiento {(x1, y1),...,(xn, yn)} donde y1,...,yn son cualitativos . La aproximaci\u00f3n m\u00e1s comp\u00fan para cuantificar la aproximaci\u00f3n de f' es el training error rate , la proporci\u00f3n de errores que haremos si aplicamos f' a los datos de entrenamiento: training_error_rate = 1 / n * [I(y0 != y'0), ..., I(yn != y'n)] Donde: * y'i : categor\u00eda que predecimos de yi utilizando f' * I(yi != y'i) : indicador que ser\u00e1 1 si yi != y'i , es decir, si son distintos , y 0 en caso contrario, si yi == y'i , es decir, si son iguales . Si es 0 quiere decir que se ha clasificado correctamente . Por lo que el training_error_rate es la fracci\u00f3n de las categor\u00edas incorrectamente clasificadas. El test error rate ser\u00e1 la media de aplicar el clasificador, donde un buen clasificador es aquel con el menor test error rate: test_error_rate = Ave(I(y0 = y'0)) Clasificador Bayesiano \u00b6 K-Nearest Neighbors \u00b6","title":"Ajuste de la Clasificaci\u00f3n"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/tema_4/ajuste_de_clasificacion/#tasa-de-error","text":"La precisi\u00f3n de un modelo depende tanto del ajuste de la regresi\u00f3n, como el caso del trade-off de sesgo y varianza, pero tambi\u00e9n depende la clasificaci\u00f3n. Supongamos que queremos estimar f bas\u00e1ndonos en los datos de entrenamiento {(x1, y1),...,(xn, yn)} donde y1,...,yn son cualitativos . La aproximaci\u00f3n m\u00e1s comp\u00fan para cuantificar la aproximaci\u00f3n de f' es el training error rate , la proporci\u00f3n de errores que haremos si aplicamos f' a los datos de entrenamiento: training_error_rate = 1 / n * [I(y0 != y'0), ..., I(yn != y'n)] Donde: * y'i : categor\u00eda que predecimos de yi utilizando f' * I(yi != y'i) : indicador que ser\u00e1 1 si yi != y'i , es decir, si son distintos , y 0 en caso contrario, si yi == y'i , es decir, si son iguales . Si es 0 quiere decir que se ha clasificado correctamente . Por lo que el training_error_rate es la fracci\u00f3n de las categor\u00edas incorrectamente clasificadas. El test error rate ser\u00e1 la media de aplicar el clasificador, donde un buen clasificador es aquel con el menor test error rate: test_error_rate = Ave(I(y0 = y'0))","title":"Tasa de error"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/tema_4/ajuste_de_clasificacion/#clasificador-bayesiano","text":"","title":"Clasificador Bayesiano"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/tema_4/ajuste_de_clasificacion/#k-nearest-neighbors","text":"","title":"K-Nearest Neighbors"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/tema_4/como_estimar/","text":"El objetivo es explorar m\u00e9todos lineares y no lineares para estimar f . Estos m\u00e9todos generalmente comparten varias caracter\u00edsticas, por lo que es interesante conocer cu\u00e1les son esas caracter\u00edsticas en com\u00fan. Se va a asumir que hemos observado un conjunto de n datos diferentes. Estas observaciones se llaman datos de entrenamiento porque se usan para entrenar o ense\u00f1ar un m\u00e9todo para estimar f . Es decir, queremos encontrar una f' de manera que Y \u2248 f'(X) para cualquier observaci\u00f3n (X, Y) . De manera gen\u00e9rica, podemos decir que la mayor\u00eda de los m\u00e9todos de aprendizaje estad\u00edstico pueden clasificarse como param\u00e9tricos y no param\u00e9tricos. M\u00e9todos param\u00e9tricos \u00b6 Los m\u00e9todos param\u00e9tricos consisten en una enfoque de dos pasos basado en modelos. Paso 1: Suposici\u00f3n Primero, haremos una supusici\u00f3n sobre la forma de f . Por ejemplo, una simple suposici\u00f3n es que f es linear en X : f(X) = \u03b20 + \u03b21X1 + \u03b22X2 + ... + \u03b2pXp. Esto es un modelo linear (se ver\u00e1 m\u00e1s adelante). Paso 2: Entrenamiento Despu\u00e9s de seleccionar un modelo, necesitamos un procedimiento que use datos entrenados o que entrene el modelo. En el caso del modelo linear, necesitamos estimar los par\u00e1metros \u03b20, \u03b21,...,\u03b2p. . Es decir, necesitamos encontrar valores para dichos par\u00e1metros tal que: Y \u2248 \u03b20 + \u03b21X1 + \u03b22X2 + ... + \u03b2pXp. El enfoque basado en modelos se describe como param\u00e9trico : disminuye el problema de estimar f a estimar un conjunto de par\u00e1metros. Asumiendo que la forma param\u00e9trica de f simplifica el problema de estimar f ya que generalmente es mucho m\u00e1s f\u00e1cil estimar un conjunto de par\u00e1metros que ajustar por completo una funci\u00f3n f . La desventaja potencial del enfoque param\u00e9trico es que el model que escogemos se ajustar\u00e1 con la verdadera (y desconocida) forma de f . Si el modelo escogido est\u00e1 muy lejos de lo que es f en realidad, entonces nuestra estimaci\u00f3n ser\u00e1 pobre . Se puede intentar resolver este problema escogiendo modelos flexibles que puedan encajar muchas posibles formas de f . Pero en general, conseguir ajustar un modelo m\u00e1s flexible requiere estimar un mayor n\u00famero de par\u00e1metros. Esos modelos son m\u00e1s complejos y pueden llevar a un fen\u00f3meno conocido como overfitting ( sobreajuste ) de los datos. Ejemplo: Queremos calcular los ingresos ( income ) de una persona en base a una funci\u00f3n que utiliza como variables de entrada los a\u00f1os de educaci\u00f3n ( education ) y el nivel de experienca ( seniority ). Tenemos datos de 30 personas. Aplicando un modelo linear , podr\u00edamos considerar esto: income \u2248 \u03b20 + \u03b21 \u00d7 education + \u03b22 \u00d7 seniority. De manera que nos tendr\u00edamos que limitar a conocer los valores de \u03b20, \u03b21 y \u03b22 , para lo que se podr\u00eda utilizar, por ejemplo, regresi\u00f3n linear cuadr\u00e1tica ( squares linear regression ) M\u00e9todos no-param\u00e9tricos \u00b6 Los m\u00e9todos no-param\u00e9tricos no hacen suposiciones expl\u00edcitas sobre la forma funcional de f . En lugar de eso, buscan una estimaci\u00f3n de f que se aproxime a los puntos de datos tanto como sea posible sin que el resultado sea demasiado ondulado o rugoso . Estas estimaciones pueden tener una mayor ventaja sobre aproximaciones param\u00e9tricas: evitando la suposici\u00f3n de una forma funcional particular de f , consiguen el potencial de, de manera precisa, ajustarse a un rango m\u00e1s grande de posibles formas de f . Cualquier aproximaci\u00f3n param\u00e9trica trae con eso la posibilidad de que la forma funcional utilizada para estimar f sea muy diferente de la verdadera f , en cuyo caso, el modelo resultado no encajar\u00e1 con los datos tan bien. Por el contrario, las aproximaciones no param\u00e9tricas evitan por completo este riesgo, ya que b\u00e1sicamente no asumen nada sobre la forma de f . Pero las aproximaciones no param\u00e9tricas s\u00ed que tienen una desventaja: ya que no reducen el problema de estimar f a un peque\u00f1o n\u00famero de par\u00e1metros, es necesario hacer much\u00edsimas observaciones (muchas m\u00e1s que las que se necesitan si se sigue una aproximaci\u00f3n param\u00e9trica) para obtener una estimaci\u00f3n precisa de f . Ejemplo: Comparativa Estos gr\u00e1ficos representan los ingresos de una persona como una funci\u00f3n de los a\u00f1os de educaci\u00f3n y la experiencia dado un conjunto de datos de 30 personas. La superficie, en cada uno de ellos, representa la relaci\u00f3n entre estas variables. En estos gr\u00e1ficos podemos ver las diferentes formas que toma la superficie, dependiendo del m\u00e9todo que se utilice para calcular f . Gr\u00e1fica de Ingresos - Linear Gr\u00e1fica de Ingresos - M\u00e9todo Param\u00e9trico - Smooth Spline Gr\u00e1fica de Ingresos - M\u00e9todo No-Param\u00e9trico - Rought Spline. El equilibro entre \"precisi\u00f3n de la predicci\u00f3n\" e \"interpretaci\u00f3n del modelo\" \u00b6 Algunos modelos son menos flexibles, o m\u00e1s restrictivos, en el sentido de que pueden producir un rango relativamente peque\u00f1o de formas para estimar f . Por ejemplo, la regresi\u00f3n linear es una estimaci\u00f3n relativamente flexible, pero s\u00f3lo puede generar funciones lineales. Entonces, \u00bfpor qu\u00e9 querr\u00edamos escoger una aproximaci\u00f3n m\u00e1s restrictiva en lugar de una m\u00e1s flexible? . Hay varias razones por las cu\u00e1les podr\u00edamos preferir un modelo m\u00e1s restrictivo. Por ejemplo, si estamos interesados en c\u00f3mo infieren los datos, el modelo linear puede ser una buena elecci\u00f3n ya que es f\u00e1cil entender la relaci\u00f3n entre Y y X1, X2, ... XP . Por el contrario, esa flexibilidad puede conllevar a estimaciones complicadas dif\u00edciles de f que hace complicado entender la asociaci\u00f3n de cualquier indicador con la respuesta. En otros casos, sin embargo, s\u00f3lo estaremos interesados en hacer una predicci\u00f3n . Si queremos por ejemplo desarrollar un algorithmo que sea capaz de predecir el precio de una acci\u00f3n, querremos un modelo flexible. \u00a1Pero cuidado! Se puede dar el caso de obtner predicciones m\u00e1s precisas usando el m\u00e9todo menos flexible. Este fen\u00f3meno, que a priori puede parecer contraintuitivo, tiene mucho que ver con el overfitting de los m\u00e9todos muy flexibles.","title":"\u00bfC\u00f3mo estimar f?"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/tema_4/como_estimar/#metodos-parametricos","text":"Los m\u00e9todos param\u00e9tricos consisten en una enfoque de dos pasos basado en modelos. Paso 1: Suposici\u00f3n Primero, haremos una supusici\u00f3n sobre la forma de f . Por ejemplo, una simple suposici\u00f3n es que f es linear en X : f(X) = \u03b20 + \u03b21X1 + \u03b22X2 + ... + \u03b2pXp. Esto es un modelo linear (se ver\u00e1 m\u00e1s adelante). Paso 2: Entrenamiento Despu\u00e9s de seleccionar un modelo, necesitamos un procedimiento que use datos entrenados o que entrene el modelo. En el caso del modelo linear, necesitamos estimar los par\u00e1metros \u03b20, \u03b21,...,\u03b2p. . Es decir, necesitamos encontrar valores para dichos par\u00e1metros tal que: Y \u2248 \u03b20 + \u03b21X1 + \u03b22X2 + ... + \u03b2pXp. El enfoque basado en modelos se describe como param\u00e9trico : disminuye el problema de estimar f a estimar un conjunto de par\u00e1metros. Asumiendo que la forma param\u00e9trica de f simplifica el problema de estimar f ya que generalmente es mucho m\u00e1s f\u00e1cil estimar un conjunto de par\u00e1metros que ajustar por completo una funci\u00f3n f . La desventaja potencial del enfoque param\u00e9trico es que el model que escogemos se ajustar\u00e1 con la verdadera (y desconocida) forma de f . Si el modelo escogido est\u00e1 muy lejos de lo que es f en realidad, entonces nuestra estimaci\u00f3n ser\u00e1 pobre . Se puede intentar resolver este problema escogiendo modelos flexibles que puedan encajar muchas posibles formas de f . Pero en general, conseguir ajustar un modelo m\u00e1s flexible requiere estimar un mayor n\u00famero de par\u00e1metros. Esos modelos son m\u00e1s complejos y pueden llevar a un fen\u00f3meno conocido como overfitting ( sobreajuste ) de los datos. Ejemplo: Queremos calcular los ingresos ( income ) de una persona en base a una funci\u00f3n que utiliza como variables de entrada los a\u00f1os de educaci\u00f3n ( education ) y el nivel de experienca ( seniority ). Tenemos datos de 30 personas. Aplicando un modelo linear , podr\u00edamos considerar esto: income \u2248 \u03b20 + \u03b21 \u00d7 education + \u03b22 \u00d7 seniority. De manera que nos tendr\u00edamos que limitar a conocer los valores de \u03b20, \u03b21 y \u03b22 , para lo que se podr\u00eda utilizar, por ejemplo, regresi\u00f3n linear cuadr\u00e1tica ( squares linear regression )","title":"M\u00e9todos param\u00e9tricos"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/tema_4/como_estimar/#metodos-no-parametricos","text":"Los m\u00e9todos no-param\u00e9tricos no hacen suposiciones expl\u00edcitas sobre la forma funcional de f . En lugar de eso, buscan una estimaci\u00f3n de f que se aproxime a los puntos de datos tanto como sea posible sin que el resultado sea demasiado ondulado o rugoso . Estas estimaciones pueden tener una mayor ventaja sobre aproximaciones param\u00e9tricas: evitando la suposici\u00f3n de una forma funcional particular de f , consiguen el potencial de, de manera precisa, ajustarse a un rango m\u00e1s grande de posibles formas de f . Cualquier aproximaci\u00f3n param\u00e9trica trae con eso la posibilidad de que la forma funcional utilizada para estimar f sea muy diferente de la verdadera f , en cuyo caso, el modelo resultado no encajar\u00e1 con los datos tan bien. Por el contrario, las aproximaciones no param\u00e9tricas evitan por completo este riesgo, ya que b\u00e1sicamente no asumen nada sobre la forma de f . Pero las aproximaciones no param\u00e9tricas s\u00ed que tienen una desventaja: ya que no reducen el problema de estimar f a un peque\u00f1o n\u00famero de par\u00e1metros, es necesario hacer much\u00edsimas observaciones (muchas m\u00e1s que las que se necesitan si se sigue una aproximaci\u00f3n param\u00e9trica) para obtener una estimaci\u00f3n precisa de f . Ejemplo: Comparativa Estos gr\u00e1ficos representan los ingresos de una persona como una funci\u00f3n de los a\u00f1os de educaci\u00f3n y la experiencia dado un conjunto de datos de 30 personas. La superficie, en cada uno de ellos, representa la relaci\u00f3n entre estas variables. En estos gr\u00e1ficos podemos ver las diferentes formas que toma la superficie, dependiendo del m\u00e9todo que se utilice para calcular f . Gr\u00e1fica de Ingresos - Linear Gr\u00e1fica de Ingresos - M\u00e9todo Param\u00e9trico - Smooth Spline Gr\u00e1fica de Ingresos - M\u00e9todo No-Param\u00e9trico - Rought Spline.","title":"M\u00e9todos no-param\u00e9tricos"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/tema_4/como_estimar/#el-equilibro-entre-precision-de-la-prediccion-e-interpretacion-del-modelo","text":"Algunos modelos son menos flexibles, o m\u00e1s restrictivos, en el sentido de que pueden producir un rango relativamente peque\u00f1o de formas para estimar f . Por ejemplo, la regresi\u00f3n linear es una estimaci\u00f3n relativamente flexible, pero s\u00f3lo puede generar funciones lineales. Entonces, \u00bfpor qu\u00e9 querr\u00edamos escoger una aproximaci\u00f3n m\u00e1s restrictiva en lugar de una m\u00e1s flexible? . Hay varias razones por las cu\u00e1les podr\u00edamos preferir un modelo m\u00e1s restrictivo. Por ejemplo, si estamos interesados en c\u00f3mo infieren los datos, el modelo linear puede ser una buena elecci\u00f3n ya que es f\u00e1cil entender la relaci\u00f3n entre Y y X1, X2, ... XP . Por el contrario, esa flexibilidad puede conllevar a estimaciones complicadas dif\u00edciles de f que hace complicado entender la asociaci\u00f3n de cualquier indicador con la respuesta. En otros casos, sin embargo, s\u00f3lo estaremos interesados en hacer una predicci\u00f3n . Si queremos por ejemplo desarrollar un algorithmo que sea capaz de predecir el precio de una acci\u00f3n, querremos un modelo flexible. \u00a1Pero cuidado! Se puede dar el caso de obtner predicciones m\u00e1s precisas usando el m\u00e9todo menos flexible. Este fen\u00f3meno, que a priori puede parecer contraintuitivo, tiene mucho que ver con el overfitting de los m\u00e9todos muy flexibles.","title":"El equilibro entre \"precisi\u00f3n de la predicci\u00f3n\" e \"interpretaci\u00f3n del modelo\""},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/tema_4/introduccion/","text":"An Introduction to Statistical Learning , Gareth James \u2022 Daniela Witten \u2022 Trevor Hastie Robert Tibshirani El aprendizaje estad\u00edstico supervisado consiste, en general, en construir un modelo estad\u00edstico para predecir o estimar unos datos de salida (output) basados en uno o m\u00e1s datos de entrada (input). Por otro lado, el aprendizaje estad\u00edstico no supervisado , tiene el mismo objetivo pero , aunque s\u00ed que se tienen en cuenta unos datos de entrada, no se tienen en cuenta los datos de salida. A pesar de esto, se pueden establecer relaciones de esos datos. Imaginemos que trabajamos en un departamento de ventas y queremos conocer la relaci\u00f3n entre publicidad y ventas, para saber ajustar presupuestos publicitarios (el dinero destinado a publicidad) e incrementar las ventas. Nuestro objetivo ser\u00eda desarrollar un modelo preciso que pueda precedir las ventas dados tres tipos de medios: televisi\u00f3n, radio y peri\u00f3dico. Los datos de entrada son conocidos por: variables de entrada ( input variables ), variables independientes, ( independent variables ) caracter\u00edsticas ( features ) o simplemente variables ( variables ) Los datos de salida son conocidos por: variable de salida ( output variable ), respuesta ( response ), o variable dependiente ( dependent variable ) input X1: presupuesto para televisi\u00f3n X2: presupuesto para radio X3: presupuesto para peri\u00f3dico output Y: ventas Generalmente hablando, si observamos una respuesta Y y un n\u00famero p de de variables independientes ( X1, X2... Xp ), asumimos que hay una relaci\u00f3n entre Y y X = (X1, X2,...,Xp) : Y = f(X) + e e ser\u00eda el error , que es independiente de X y cuya media es 0 f representa la informaci\u00f3n sistem\u00e1tica que X nos da sobre Y En esencia, el aprendizaje estad\u00edstico se refiere en las aproximaciones para estimar f . Por esto, veremos: Conceptos te\u00f3ricos a la hora de estimar f Herramientas para evaluar las estimaciones obtenidas","title":"Introducci\u00f3n al Aprendizaje Supervisado"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/tema_4/por_que_estimar/","text":"Predicci\u00f3n \u00b6 La estimaci\u00f3n permite predecir un valor Y en aquellas situaciones donde tenemos informaci\u00f3n disponible sobre X , pero no es tan sencillo obtener Y . Supongamos que X1, ...Xp son caracter\u00edsticas de una muestra de sangre de un paciente que se pueden medir f\u00e1cilmente en un laboratorio. Y es la variable que codifica el riesgo del paciente de tener una reacci\u00f3n adversa a un medicamento. Lo natural es buscar c\u00f3mo precedir Y utilizando X , ya que podemos no dar el medicamento en cuesti\u00f3n a los pacientes que tienen un alto riesgo de tener una reacci\u00f3n adversa, es decir, pacientes para los que la estimaci\u00f3n de Y es alta . f' : representa la estimaci\u00f3n de f Y' : representa la predicci\u00f3n resultante de Y Y' = f'(X) Normalmente f' , act\u00faa como una caja negra (es decir, no sabemos lo que hace dentro , sino que solo sabemos el input y el output) Decimos que hay un error porque, realmente, f' no va actuar exactamente como f . Encontraremos dos tipos de errores: Error reducible: Podemos conseguir que Y' se parezca m\u00e1s a Y modificando f' , obteniendo as\u00ed un mejor resultado tras cada modificaci\u00f3n. Error irreducible: Por mucho que modifiquemos, optimicemos y mejoremos f' , siempre habr\u00e1, por definici\u00f3n, algo de error, ya que por definici\u00f3n, decimos que es imposible predecir Y . No matter how well we estimate f , we cannot reduce the error introduced by e Sobre el error irreducible, sabemos que: Tiende a 0 , es decir, siempre es mayor que 0 e puede contener variables que no pueden ser medidas, pero que pueden ser \u00fatiles para predecir Y . Pero como no podemos medirlas, f no puede usarlas en la predicci\u00f3n. e puede contener variaciones que no tampoco pueden ser medidas, como por ejemplo, el riesgo de que un medicamento provoque una reacci\u00f3n en un paciente, pudiendo variar esta reacci\u00f3n de un d\u00eda a otro en relaci\u00f3n al estado an\u00edmico de \u00e9ste. expected_value = E(Y - Y')^2 = E(f(X) + e - f'(x))^2 = E(f(X) - f'(x))^2 + Var(e) d\u00f3nde: error_reducible = E(f(X) - f'(x))^2 error_irreducible = Var(e) = varianza asociada con e Ejemplo: Consideremos que una compa\u00f1\u00eda esta interesada en conducir una campa\u00f1a de marketing. El objetivo es identificar a personas que vayan a responder de manera positiva a un correo, bas\u00e1ndonos en observaciones de variables demogr\u00e1ficas medidas en cada una de esas personas. En este caso, las variables demogr\u00e1ficas se pueden utilizar como indicadores , y la respuesta a la campa\u00f1a de m\u00e1rketing (positiva o negativa) se utiliza como dato de salida . La compa\u00f1\u00eda no est\u00e1 interesada en tener un conocimiento profundo de la relaci\u00f3n entre los indicadores de cada persona y la respuesta, sino que simplemente quiere un modelo preciso para predecir la respuesta utilizando los indicadores. Inferencia \u00b6 Nos interesa saber de qu\u00e9 manera le afecta a Y los distintos valores que puede tomar X . En esta situaci\u00f3n, aunque queremos estimar f , el verdadero objetivo no es hacer predicciones de Y . En lugar de eso, queremos entender la relaci\u00f3n entre X e Y o, para ser m\u00e1s espec\u00edficos, entender c\u00f3mo cambia Y en funci\u00f3n de X1, ....XP . En este caso, no podemos tratar a f' como una caja negra , ya que necesitamos saber qu\u00e9 hace . \u00bfQu\u00e9 indicadores ( predictors ) est\u00e1n relacionados con la respuesta? Es muy com\u00fan el caso en el que s\u00f3lo una peque\u00f1a porci\u00f3n de los indicadores disponbiles est\u00e1n relacionados con Y considerablemente. Identificar qu\u00e9 indicadores son los importantes entre un gran n\u00famero de variables posibles puede ser incre\u00edblemente \u00fatil dependiendo de la aplicaci\u00f3n. \u00bfCu\u00e1l es la relaci\u00f3n entre la respuesta y cada indicador? Algunos indicadores pueden tener una relaci\u00f3n positiva con Y , en el sentido de que incrementar el indicador est\u00e1 asociado con incrementar los valores de Y . Otros indicadores pueden tener una relaci\u00f3n contraria. Dependiendo de la complejidad de f , la relaci\u00f3n entre la respuesta y un indicador puede tambi\u00e9n depender de los valores de otros indicadores. \u00bfPuede la relaci\u00f3n entre Y y cada indicador abreviarse correctamente utilizando una ecuaci\u00f3n linear, o es m\u00e1s complicado? La mayor\u00eda de m\u00e9todos para estimar f toman una forma lineal. En algunas situaciones, este supuesto o hip\u00f3tesis es razonable o incluso deseable, pero es muy posible que la relaci\u00f3n sea mas complicada, en cuyo caso, el modelo linear puede no darnos una representaci\u00f3n precisa de esta relaci\u00f3n entre input y output. Ejemplo: Queremos modelar la marca de un producto que un consumidor puede comprar bas\u00e1ndonos en variables como el precio , la ubicaci\u00f3n de la tienda , los niveles de descuento o el precio de la competencia . En esta situaci\u00f3n estar\u00edamos m\u00e1s interesados en c\u00f3mo cada una de las variables individuales afectan a la probabilidad de que se produzca una compra. Por ejemplo, \u00bfqu\u00e9 efecto tiene el cambio del precio de un producto con respecto a las ventas? En algunos casos, es posible que un modelo se utilice tanto para predicci\u00f3n como para inferencia de datos. Dependiendo de si el objetivo final es predicci\u00f3n, inferencia o una combinaci\u00f3n de ambos, se utilizar\u00e1n diferentes m\u00e9todos para estimar f . Por ejemplo, los modelos lineales son relativamente simples para calcular inferencia, pero pueden no ser tan precisos para hacer predicciones como otras aproximaciones.","title":"\u00bfPor qu\u00e9 estimar f?"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/tema_4/por_que_estimar/#prediccion","text":"La estimaci\u00f3n permite predecir un valor Y en aquellas situaciones donde tenemos informaci\u00f3n disponible sobre X , pero no es tan sencillo obtener Y . Supongamos que X1, ...Xp son caracter\u00edsticas de una muestra de sangre de un paciente que se pueden medir f\u00e1cilmente en un laboratorio. Y es la variable que codifica el riesgo del paciente de tener una reacci\u00f3n adversa a un medicamento. Lo natural es buscar c\u00f3mo precedir Y utilizando X , ya que podemos no dar el medicamento en cuesti\u00f3n a los pacientes que tienen un alto riesgo de tener una reacci\u00f3n adversa, es decir, pacientes para los que la estimaci\u00f3n de Y es alta . f' : representa la estimaci\u00f3n de f Y' : representa la predicci\u00f3n resultante de Y Y' = f'(X) Normalmente f' , act\u00faa como una caja negra (es decir, no sabemos lo que hace dentro , sino que solo sabemos el input y el output) Decimos que hay un error porque, realmente, f' no va actuar exactamente como f . Encontraremos dos tipos de errores: Error reducible: Podemos conseguir que Y' se parezca m\u00e1s a Y modificando f' , obteniendo as\u00ed un mejor resultado tras cada modificaci\u00f3n. Error irreducible: Por mucho que modifiquemos, optimicemos y mejoremos f' , siempre habr\u00e1, por definici\u00f3n, algo de error, ya que por definici\u00f3n, decimos que es imposible predecir Y . No matter how well we estimate f , we cannot reduce the error introduced by e Sobre el error irreducible, sabemos que: Tiende a 0 , es decir, siempre es mayor que 0 e puede contener variables que no pueden ser medidas, pero que pueden ser \u00fatiles para predecir Y . Pero como no podemos medirlas, f no puede usarlas en la predicci\u00f3n. e puede contener variaciones que no tampoco pueden ser medidas, como por ejemplo, el riesgo de que un medicamento provoque una reacci\u00f3n en un paciente, pudiendo variar esta reacci\u00f3n de un d\u00eda a otro en relaci\u00f3n al estado an\u00edmico de \u00e9ste. expected_value = E(Y - Y')^2 = E(f(X) + e - f'(x))^2 = E(f(X) - f'(x))^2 + Var(e) d\u00f3nde: error_reducible = E(f(X) - f'(x))^2 error_irreducible = Var(e) = varianza asociada con e Ejemplo: Consideremos que una compa\u00f1\u00eda esta interesada en conducir una campa\u00f1a de marketing. El objetivo es identificar a personas que vayan a responder de manera positiva a un correo, bas\u00e1ndonos en observaciones de variables demogr\u00e1ficas medidas en cada una de esas personas. En este caso, las variables demogr\u00e1ficas se pueden utilizar como indicadores , y la respuesta a la campa\u00f1a de m\u00e1rketing (positiva o negativa) se utiliza como dato de salida . La compa\u00f1\u00eda no est\u00e1 interesada en tener un conocimiento profundo de la relaci\u00f3n entre los indicadores de cada persona y la respuesta, sino que simplemente quiere un modelo preciso para predecir la respuesta utilizando los indicadores.","title":"Predicci\u00f3n"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/tema_4/por_que_estimar/#inferencia","text":"Nos interesa saber de qu\u00e9 manera le afecta a Y los distintos valores que puede tomar X . En esta situaci\u00f3n, aunque queremos estimar f , el verdadero objetivo no es hacer predicciones de Y . En lugar de eso, queremos entender la relaci\u00f3n entre X e Y o, para ser m\u00e1s espec\u00edficos, entender c\u00f3mo cambia Y en funci\u00f3n de X1, ....XP . En este caso, no podemos tratar a f' como una caja negra , ya que necesitamos saber qu\u00e9 hace . \u00bfQu\u00e9 indicadores ( predictors ) est\u00e1n relacionados con la respuesta? Es muy com\u00fan el caso en el que s\u00f3lo una peque\u00f1a porci\u00f3n de los indicadores disponbiles est\u00e1n relacionados con Y considerablemente. Identificar qu\u00e9 indicadores son los importantes entre un gran n\u00famero de variables posibles puede ser incre\u00edblemente \u00fatil dependiendo de la aplicaci\u00f3n. \u00bfCu\u00e1l es la relaci\u00f3n entre la respuesta y cada indicador? Algunos indicadores pueden tener una relaci\u00f3n positiva con Y , en el sentido de que incrementar el indicador est\u00e1 asociado con incrementar los valores de Y . Otros indicadores pueden tener una relaci\u00f3n contraria. Dependiendo de la complejidad de f , la relaci\u00f3n entre la respuesta y un indicador puede tambi\u00e9n depender de los valores de otros indicadores. \u00bfPuede la relaci\u00f3n entre Y y cada indicador abreviarse correctamente utilizando una ecuaci\u00f3n linear, o es m\u00e1s complicado? La mayor\u00eda de m\u00e9todos para estimar f toman una forma lineal. En algunas situaciones, este supuesto o hip\u00f3tesis es razonable o incluso deseable, pero es muy posible que la relaci\u00f3n sea mas complicada, en cuyo caso, el modelo linear puede no darnos una representaci\u00f3n precisa de esta relaci\u00f3n entre input y output. Ejemplo: Queremos modelar la marca de un producto que un consumidor puede comprar bas\u00e1ndonos en variables como el precio , la ubicaci\u00f3n de la tienda , los niveles de descuento o el precio de la competencia . En esta situaci\u00f3n estar\u00edamos m\u00e1s interesados en c\u00f3mo cada una de las variables individuales afectan a la probabilidad de que se produzca una compra. Por ejemplo, \u00bfqu\u00e9 efecto tiene el cambio del precio de un producto con respecto a las ventas? En algunos casos, es posible que un modelo se utilice tanto para predicci\u00f3n como para inferencia de datos. Dependiendo de si el objetivo final es predicci\u00f3n, inferencia o una combinaci\u00f3n de ambos, se utilizar\u00e1n diferentes m\u00e9todos para estimar f . Por ejemplo, los modelos lineales son relativamente simples para calcular inferencia, pero pueden no ser tan precisos para hacer predicciones como otras aproximaciones.","title":"Inferencia"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/tema_4/quality_of_fit/","text":"Quality over Fit \u00b6 No existe un m\u00e9todo perfecto, sino que el reto consiste en encontrar la mejor aproximaci\u00f3n para encontrar una soluci\u00f3n al problema que nos planteamos. Para evaluar la eficiencia de un m\u00e9todo de aprendizaje estadistico dado un conjunto de datos, necesitamos alguna manera de medir c\u00f3mo de bien las predicciones de dicho modelo encajan con los datos observados. Es decir, necesitamos quantificar c\u00f3mo de cerca est\u00e1 cada respuesta de una observaci\u00f3n con el verdadero valor de esa observaci\u00f3n. Lo m\u00e1s utilizado es el mean squared error (MSE): MSE = 1 / n * [(yi \u2212 f'(xi))^2, ..., (yn \u2212 f'(xn))^2] Donde: f' es la predicci\u00f3n n es el n\u00famero de observaciones cada xi es una observaci\u00f3n cada yi es la respuesta a una observaci\u00f3n El MSE ser\u00e1 peque\u00f1o si las respuestas de la predicci\u00f3n son muy parecidas a las verdaderas, y ser\u00e1 grande si estas difieren de manera substancial. Lo que nos interesa es: la precisi\u00f3n de las predicciones que obtener cuando aplicamos el m\u00e9todo a datos de prueba que no conocemos previamente . Estos es porque, si por ejemplo, tenemos los datos cl\u00ednicos de un n\u00famero de pacientes y ya sabemos si esos pacientes tienen o no diabetes, lo que nos interesa es que el m\u00e9todo prediga de manera precisa si futuros pacientes (datos que no conocemos) van a padecer o no diabetes en base a esas variables (es decir, no nos interesa saber si el m\u00e9todo es bueno para pacientes que ya sabemos si tienen o no diabetes) Lo que queremos saber es si f'(x0) es aproximadamente igual a y0 donde (x0, y0) es una observaci\u00f3n que no se ha utilizado para entrenar el m\u00e9todo. Queremos elegir el m\u00e9todo que nos d\u00e9 el menor test MSE (error en los datos de prueba), opuesto al menor training MSE (error en los datos de entrenamiento). Para ello, lo que podemos hacer para elegir entre un m\u00e9todo u otro es elegir aqu\u00e9l que tenga la media del test MSE m\u00e1s peque\u00f1a. Ave(y0 \u2212 f('x0))^2 Pero, \u00bfC\u00f3mo podemos seleccionar el m\u00e9todo que minimize el test MSE ? Depender\u00e1 de si conocemos o no las observaciones, o los datos de entrenamiento, disponibles. Si conocemos las observaciones: Evaluar las pruebas y seleccionar el m\u00e9todo en el cual el test MSE es menor. Si no conocemos las observaciones: Seleccionar un m\u00e9todo que que minimice el training MSE . Pero esto puede ser fr\u00e1gil, ya que es posible que el test MSE y el training MSE est\u00e9n muy relacionados, y, por esto, no est\u00e1 garantizado que el m\u00e9todo con el menor training MSE tenga tambi\u00e9n el menor test MSE . Esto podemos ver que sucede en este ejemplo: Estimaciones de f con diferentes m\u00e9todos: L\u00ednea negra: datos simulados de f L\u00ednea naranja: regresi\u00f3n linear L\u00edneas azul y verde: smoothing spline fit Flexibilidad vs MSE: L\u00ednea gris: Training MSE L\u00ednea roja: Test MSE L\u00ednea horizontal de puntos: m\u00ednimo test MSE de todos los m\u00e9todos Cuadrados: Representan los training MSE y test MSE respectivamente de los tres m\u00e9todos (naranja, azul y verde) de la gr\u00e1fica anterior Aqu\u00ed, como f no es linear, la l\u00ednea naranja de la primera gr\u00e1fica no es lo suficientemente flexible para estimar bien f . La l\u00ednea verde tiene el menor training MSE de los tres m\u00e9todos, como vemos que corresponde a la curva m\u00e1s flexible de la primera gr\u00e1fica. Otro ejemplo con unos datos que se aproximan m\u00e1s a una funci\u00f3n linear: Que podemos ver c\u00f3mo de diferente es para datos que no encajan con una funci\u00f3n linear: Overfitting \u00b6 En la segunda gr\u00e1fica podemos ver c\u00f3mo, de manera que la flexibilidad del m\u00e9todo estat\u00edstico aumenta, hay un decrecimiento mon\u00f3tono del training MSE y una la test MSE tiene forma de U. Esta es una propiedad fundamental del aprendizaje estad\u00edsitco: independientemente de un conjunto de datos praticulares e independientemente del m\u00e9todo estad\u00edstico utilizado, de manera que la flexibilidad aumenta, el training MSE disminuye, pero puede que el test MSE no. Cuando Un m\u00e9todo produce un peque\u00f1o training MSE pero un gran test MSE , estaremos hablando de overfitting . Esto sucede porque el procedimiento utilizado est\u00e1 trabajando demasiado duro en encontrar un patr\u00f3n en los datos de entrenamiento, y puede estar usando algunos patrones que pasan por casualidad o azar , en lugar de ser verdaderas propiedades de f . Cuando hay overfit , el test MSE suele ser muy grande porque los supuestos patrones que suceden por casualidad no van a estar en los datos de prueba. Independientemente de que ocurra o no overfitting, casi siempre hemos de esperar que el training MSE sea menor que el test MSE porque la mayor\u00eda de los m\u00e9todos estad\u00edsticos, de manera directa o indirecta, buscan minimizar el training MSE .","title":"Medir la calidad de ajuste"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/tema_4/quality_of_fit/#quality-over-fit","text":"No existe un m\u00e9todo perfecto, sino que el reto consiste en encontrar la mejor aproximaci\u00f3n para encontrar una soluci\u00f3n al problema que nos planteamos. Para evaluar la eficiencia de un m\u00e9todo de aprendizaje estadistico dado un conjunto de datos, necesitamos alguna manera de medir c\u00f3mo de bien las predicciones de dicho modelo encajan con los datos observados. Es decir, necesitamos quantificar c\u00f3mo de cerca est\u00e1 cada respuesta de una observaci\u00f3n con el verdadero valor de esa observaci\u00f3n. Lo m\u00e1s utilizado es el mean squared error (MSE): MSE = 1 / n * [(yi \u2212 f'(xi))^2, ..., (yn \u2212 f'(xn))^2] Donde: f' es la predicci\u00f3n n es el n\u00famero de observaciones cada xi es una observaci\u00f3n cada yi es la respuesta a una observaci\u00f3n El MSE ser\u00e1 peque\u00f1o si las respuestas de la predicci\u00f3n son muy parecidas a las verdaderas, y ser\u00e1 grande si estas difieren de manera substancial. Lo que nos interesa es: la precisi\u00f3n de las predicciones que obtener cuando aplicamos el m\u00e9todo a datos de prueba que no conocemos previamente . Estos es porque, si por ejemplo, tenemos los datos cl\u00ednicos de un n\u00famero de pacientes y ya sabemos si esos pacientes tienen o no diabetes, lo que nos interesa es que el m\u00e9todo prediga de manera precisa si futuros pacientes (datos que no conocemos) van a padecer o no diabetes en base a esas variables (es decir, no nos interesa saber si el m\u00e9todo es bueno para pacientes que ya sabemos si tienen o no diabetes) Lo que queremos saber es si f'(x0) es aproximadamente igual a y0 donde (x0, y0) es una observaci\u00f3n que no se ha utilizado para entrenar el m\u00e9todo. Queremos elegir el m\u00e9todo que nos d\u00e9 el menor test MSE (error en los datos de prueba), opuesto al menor training MSE (error en los datos de entrenamiento). Para ello, lo que podemos hacer para elegir entre un m\u00e9todo u otro es elegir aqu\u00e9l que tenga la media del test MSE m\u00e1s peque\u00f1a. Ave(y0 \u2212 f('x0))^2 Pero, \u00bfC\u00f3mo podemos seleccionar el m\u00e9todo que minimize el test MSE ? Depender\u00e1 de si conocemos o no las observaciones, o los datos de entrenamiento, disponibles. Si conocemos las observaciones: Evaluar las pruebas y seleccionar el m\u00e9todo en el cual el test MSE es menor. Si no conocemos las observaciones: Seleccionar un m\u00e9todo que que minimice el training MSE . Pero esto puede ser fr\u00e1gil, ya que es posible que el test MSE y el training MSE est\u00e9n muy relacionados, y, por esto, no est\u00e1 garantizado que el m\u00e9todo con el menor training MSE tenga tambi\u00e9n el menor test MSE . Esto podemos ver que sucede en este ejemplo: Estimaciones de f con diferentes m\u00e9todos: L\u00ednea negra: datos simulados de f L\u00ednea naranja: regresi\u00f3n linear L\u00edneas azul y verde: smoothing spline fit Flexibilidad vs MSE: L\u00ednea gris: Training MSE L\u00ednea roja: Test MSE L\u00ednea horizontal de puntos: m\u00ednimo test MSE de todos los m\u00e9todos Cuadrados: Representan los training MSE y test MSE respectivamente de los tres m\u00e9todos (naranja, azul y verde) de la gr\u00e1fica anterior Aqu\u00ed, como f no es linear, la l\u00ednea naranja de la primera gr\u00e1fica no es lo suficientemente flexible para estimar bien f . La l\u00ednea verde tiene el menor training MSE de los tres m\u00e9todos, como vemos que corresponde a la curva m\u00e1s flexible de la primera gr\u00e1fica. Otro ejemplo con unos datos que se aproximan m\u00e1s a una funci\u00f3n linear: Que podemos ver c\u00f3mo de diferente es para datos que no encajan con una funci\u00f3n linear:","title":"Quality over Fit"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/tema_4/quality_of_fit/#overfitting","text":"En la segunda gr\u00e1fica podemos ver c\u00f3mo, de manera que la flexibilidad del m\u00e9todo estat\u00edstico aumenta, hay un decrecimiento mon\u00f3tono del training MSE y una la test MSE tiene forma de U. Esta es una propiedad fundamental del aprendizaje estad\u00edsitco: independientemente de un conjunto de datos praticulares e independientemente del m\u00e9todo estad\u00edstico utilizado, de manera que la flexibilidad aumenta, el training MSE disminuye, pero puede que el test MSE no. Cuando Un m\u00e9todo produce un peque\u00f1o training MSE pero un gran test MSE , estaremos hablando de overfitting . Esto sucede porque el procedimiento utilizado est\u00e1 trabajando demasiado duro en encontrar un patr\u00f3n en los datos de entrenamiento, y puede estar usando algunos patrones que pasan por casualidad o azar , en lugar de ser verdaderas propiedades de f . Cuando hay overfit , el test MSE suele ser muy grande porque los supuestos patrones que suceden por casualidad no van a estar en los datos de prueba. Independientemente de que ocurra o no overfitting, casi siempre hemos de esperar que el training MSE sea menor que el test MSE porque la mayor\u00eda de los m\u00e9todos estad\u00edsticos, de manera directa o indirecta, buscan minimizar el training MSE .","title":"Overfitting"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/tema_4/regresion_y_clasificacion/","text":"Cualitativo vs Cuantitativo \u00b6 Las variables pueden ser de dos tipos: num\u00e9ricas o categ\u00f3ricas. Las num\u00e9ricas tambi\u00e9n son llamadas cuantitativas ( quantitatives ) y las categ\u00f3ricas, cualitativas ( qualitative ) Num\u00e9ricas: Edad, peso, altura, distancia recorrida... Categ\u00f3ricas: Ciudad, color, marca... Regresi\u00f3n vs Clasificaci\u00f3n \u00b6 Los problemas de regresi\u00f3n son aquellos que dan una respuesta cuantitativa Los problemas de clasificaci\u00f3n son aquellos que dan una respuesta cualitativa Sin embargo, hay m\u00e9todos que sirven tanto para problemas de regresi\u00f3n como de clasificaci\u00f3n.","title":"Problemas de Regresi\u00f3n vs Problemas de Clasificaci\u00f3n"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/tema_4/regresion_y_clasificacion/#cualitativo-vs-cuantitativo","text":"Las variables pueden ser de dos tipos: num\u00e9ricas o categ\u00f3ricas. Las num\u00e9ricas tambi\u00e9n son llamadas cuantitativas ( quantitatives ) y las categ\u00f3ricas, cualitativas ( qualitative ) Num\u00e9ricas: Edad, peso, altura, distancia recorrida... Categ\u00f3ricas: Ciudad, color, marca...","title":"Cualitativo vs Cuantitativo"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/tema_4/regresion_y_clasificacion/#regresion-vs-clasificacion","text":"Los problemas de regresi\u00f3n son aquellos que dan una respuesta cuantitativa Los problemas de clasificaci\u00f3n son aquellos que dan una respuesta cualitativa Sin embargo, hay m\u00e9todos que sirven tanto para problemas de regresi\u00f3n como de clasificaci\u00f3n.","title":"Regresi\u00f3n vs Clasificaci\u00f3n"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/tema_4/sesgo_y_varianza/","text":"Cuando se produce una curva de test MSE con forma de U, suele ser el resultado de dos propiedades que compiten en el m\u00e9todo de aprendizaje estad\u00edstico. No nos vamos a centrar en la comprobaci\u00f3n matem\u00e1tica, pero es posible saber que el esperado test MSE para un valor dado x0 puede ser descompuesto en la suma de tres cantidades fundamentales : La varianza de f'(x0) : Se refiere a la cantidad de f' que puede variar si se estima usando un conjunto de datos diferente. Diferentes conjuntos de datos producen diferentes f' , pero lo ideal ser\u00eda que f' no variara demasiado (que sea menos flexible). Los m\u00e9todos estad\u00edsticos m\u00e1s flexibles tienen mayor varianza . El sesgo al cuadrado de f'(x0) : Se refiere al error introducido al aproximar un problema de la vida real . Por ejemplo, si usamos una relaci\u00f3n lineal entre Y y X1, X2, ..., XP , ya que es muy raro que en la vida real haya una relaci\u00f3n lineal tan sencilla, estaremos introduciendo un bias o sesgo al estimar f . Los m\u00e9todos estad\u00edsticos m\u00e1s flexibles tienen menor bias La varianza del error e Con esto, tenemos que la covarianza de y0 y f'(x0) es igual a la varianza de f'(x0) m\u00e1s el sesgo al cuadrado de f'(x0) m\u00e1s la varianza del error e : La media del test MSE = covarianza de y0 y f'(x0) : Cov(y0, f'x(0)) = E[(y0 - f'x(0))^2] E[(y0 - f'x(0))^2] = var(f'(x0)) + [Bias(f'(x0))]^2 + var(e) Con esta ecuaci\u00f3n, vemos que para miniminzar el test MSE , necesitamos elegir un m\u00e9todo que de manera simult\u00e1nea consiga una menor varianza y un menor sesgo . Como la varianza es siempre mayor o igual que 0, y el cuadrado del sesgo (bias) tambi\u00e9n, el test MSE nunca va a estar por debajo de var(e) , que es el error irreducible . La relaci\u00f3n entre sesgo y varianza nos dice que un buen m\u00e9todo estad\u00edstico producir\u00e1 un resultado con una varianza baja pero tambi\u00e9n un sesgo al cuadrado bajo. Esto es un reto, ya que es muy f\u00e1cil obtener un m\u00e9todo con un sesgo muy bajo pero una varianza muy alta, o un m\u00e9todo con una varianza muy baja pero un bias muy alto.","title":"Equilibrio entre sesgo (bias) y varianza"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/tema_4/supervisado_vs_no_supervisado/","text":"La mayor\u00eda de los problemas de aprendizaje estad\u00edstico se pueden clasificar en una de estas dos categor\u00edas: supervisado y no supervisado. Aprendizaje Supervisado \u00b6 En esta modalidad, se entrena el modelo a trav\u00e9s de ciertas caracter\u00edsticas o datos de entrada (input) y de ciertas respuestas (output) para poder inferir o predecir datos. Dentro del aprendizaje supervisado existen dos tipos: regresi\u00f3n y clasificaci\u00f3n. Regresi\u00f3n: en el caso de que la variable repuesta sea continua. Clasificaci\u00f3n: en el caso de que la variable respuesta sea nominal. Aprendizaje No Supervisado \u00b6 Al contrario de como ocurre en el aprendizaje supervisado, no se tiene en cuenta el output o respuesta, sino que s\u00f3lo se tienen en cuenta los datos de entrada. Lo que ocurre es que los modelos se encargan de agrupar datos seg\u00fan estas caracter\u00edsticas, por aquellas que son similares . Esto se conoce como cluster analysis , o clustering.","title":"Aprendizaje Supervisado vs Aprendizaje No Supervisado"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/tema_4/supervisado_vs_no_supervisado/#aprendizaje-supervisado","text":"En esta modalidad, se entrena el modelo a trav\u00e9s de ciertas caracter\u00edsticas o datos de entrada (input) y de ciertas respuestas (output) para poder inferir o predecir datos. Dentro del aprendizaje supervisado existen dos tipos: regresi\u00f3n y clasificaci\u00f3n. Regresi\u00f3n: en el caso de que la variable repuesta sea continua. Clasificaci\u00f3n: en el caso de que la variable respuesta sea nominal.","title":"Aprendizaje Supervisado"},{"location":"asignaturas/primer_cuatrimestre/modelado_estadistico_de_datos/tema_4/supervisado_vs_no_supervisado/#aprendizaje-no-supervisado","text":"Al contrario de como ocurre en el aprendizaje supervisado, no se tiene en cuenta el output o respuesta, sino que s\u00f3lo se tienen en cuenta los datos de entrada. Lo que ocurre es que los modelos se encargan de agrupar datos seg\u00fan estas caracter\u00edsticas, por aquellas que son similares . Esto se conoce como cluster analysis , o clustering.","title":"Aprendizaje No Supervisado"},{"location":"asignaturas/primer_cuatrimestre/programacion_en_entornos_de_datos/ejercicios/","text":"Ejercicios tema 1 \u00b6 1. Instalar Jupyter Notebooks \u00b6","title":"Ejercicios"},{"location":"asignaturas/primer_cuatrimestre/programacion_en_entornos_de_datos/ejercicios/#ejercicios-tema-1","text":"","title":"Ejercicios tema 1"},{"location":"asignaturas/primer_cuatrimestre/programacion_en_entornos_de_datos/ejercicios/#1-instalar-jupyter-notebooks","text":"","title":"1. Instalar Jupyter Notebooks"},{"location":"asignaturas/primer_cuatrimestre/programacion_en_entornos_de_datos/tema_1/","text":"Introducci\u00f3n a la programaci\u00f3n en entornos de datos \u00b6","title":"Tema 1"},{"location":"asignaturas/primer_cuatrimestre/programacion_en_entornos_de_datos/tema_1/#introduccion-a-la-programacion-en-entornos-de-datos","text":"","title":"Introducci\u00f3n a la programaci\u00f3n en entornos de datos"}]}